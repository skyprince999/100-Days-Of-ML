{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected = True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "pd.set_option('max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python35.zip', '/usr/lib/python3.5', '/usr/lib/python3.5/plat-x86_64-linux-gnu', '/usr/lib/python3.5/lib-dynload', '', '/usr/local/lib/python3.5/dist-packages', '/usr/local/lib/python3.5/site-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.5/dist-packages/IPython/extensions', '/home/jupyter/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/kernel/__init__.py:13: ShimWarning:\n",
      "\n",
      "The `IPython.kernel` package has been deprecated since IPython 4.0.You should import from ipykernel or jupyter_client instead.\n",
      "\n",
      "WARNING: AstropyDeprecationWarning: astropy.utils.compat.futures is now deprecated - use concurrent.futures instead [astropy.utils.compat.futures]\n",
      "Using TensorFlow backend.\n",
      "Generating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "/usr/local/lib/python3.5/dist-packages/nltk/twitter/__init__.py:22: UserWarning:\n",
      "\n",
      "The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file\n",
      "Loading multi\n",
      "Loading pyfs\n",
      "Loading kwallet\n",
      "Loading Windows (alt)\n",
      "Loading Google\n",
      "Loading Gnome\n",
      "Loading keyczar\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/novice/__init__.py:103: UserWarning:\n",
      "\n",
      "The `skimage.novice` module was deprecated in version 0.14. It will be removed in 0.16.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/viewer/__init__.py:6: UserWarning:\n",
      "\n",
      "Viewer requires Qt\n",
      "\n",
      "/usr/lib/python3.5/pkgutil.py:101: VisibleDeprecationWarning:\n",
      "\n",
      "zmq.eventloop.minitornado is deprecated in pyzmq 14.0 and will be removed.\n",
      "    Install tornado itself to use zmq with the tornado IOLoop.\n",
      "    \n",
      "\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning:\n",
      "\n",
      "numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDROM               brain_numpy_core_fromnumeric joblib              quopri\n",
      "Crypto              brain_numpy_core_function_base json                random\n",
      "DLFCN               brain_numpy_core_multiarray json5               re\n",
      "IN                  brain_numpy_core_numeric jsonschema          readline\n",
      "IPython             brain_numpy_core_numerictypes jupyter             reprlib\n",
      "PIL                 brain_numpy_core_umath jupyter_aihub_deploy_extension requests\n",
      "TBB                 brain_numpy_ndarray jupyter_client      requests_oauthlib\n",
      "TYPES               brain_numpy_random_mtrand jupyter_console     resource\n",
      "__future__          brain_numpy_utils   jupyter_contrib_core retrying\n",
      "_ast                brain_pkg_resources jupyter_contrib_nbextensions rlcompleter\n",
      "_bisect             brain_pytest        jupyter_core        rmagic\n",
      "_bootlocale         brain_qt            jupyter_highlight_selected_word rsa\n",
      "_bz2                brain_random        jupyter_http_over_ws runpy\n",
      "_cffi_backend       brain_re            jupyter_nbextensions_configurator sched\n",
      "_codecs             brain_six           jupyterlab          scipy\n",
      "_codecs_cn          brain_ssl           jupyterlab_git      seaborn\n",
      "_codecs_hk          brain_subprocess    jupyterlab_server   secretstorage\n",
      "_codecs_iso2022     brain_threading     keras               select\n",
      "_codecs_jp          brain_typing        keras_applications  selectors\n",
      "_codecs_kr          brain_uuid          keras_preprocessing send2trash\n",
      "_codecs_tw          builtins            keyring             setuptools\n",
      "_collections        bz2                 keyword             shelve\n",
      "_collections_abc    cProfile            kiwisolver          shlex\n",
      "_compat_pickle      cachetools          kubernetes          shutil\n",
      "_compression        calendar            latex_envs          signal\n",
      "_crypt              certifi             lazy_object_proxy   simplegeneric\n",
      "_csv                cgi                 lib2to3             site\n",
      "_ctypes             cgitb               libfuturize         sitecustomize\n",
      "_ctypes_test        chardet             libpasteurize       six\n",
      "_curses             chunk               linecache           skimage\n",
      "_curses_panel       click               llvmlite            sklearn\n",
      "_datetime           cloudpickle         locale              smmap\n",
      "_dbm                cmath               logging             smtpd\n",
      "_dbus_bindings      cmd                 lsb_release         smtplib\n",
      "_dbus_glib_bindings code                lxml                sndhdr\n",
      "_decimal            codecs              lzma                socket\n",
      "_dummy_thread       codeop              macpath             socketserver\n",
      "_elementtree        collections         macurl2path         softwareproperties\n",
      "_functools          colorama            mailbox             spwd\n",
      "_hashlib            colorsys            mailcap             sql\n",
      "_heapq              compileall          markdown            sqlalchemy\n",
      "_imp                concurrent          markupsafe          sqlite3\n",
      "_io                 configparser        marshal             sqlparse\n",
      "_json               confuse             math                sre_compile\n",
      "_locale             containerregistry   matplotlib          sre_constants\n",
      "_lsprof             contextlib          mccabe              sre_parse\n",
      "_lzma               cookiecutter        mimetypes           ssl\n",
      "_markupbase         copy                missingno           stat\n",
      "_md5                copyreg             mistune             statistics\n",
      "_multibytecodec     crypt               mkl_fft             storemagic\n",
      "_multiprocessing    cryptography        mkl_random          string\n",
      "_opcode             csv                 mmap                stringprep\n",
      "_operator           ctypes              mock                struct\n",
      "_osx_support        curl                modulefinder        subprocess\n",
      "_pickle             curses              more_itertools      sunau\n",
      "_plotly_future_     cv2                 multiprocessing     symbol\n",
      "_plotly_utils       cycler              nbconvert           sympyprinting\n",
      "_posixsubprocess    cythonmagic         nbdime              symtable\n",
      "_pydecimal          daal                nbformat            sys\n",
      "_pyio               datetime            netrc               sysconfig\n",
      "_pyrsistent_version dateutil            networkx            syslog\n",
      "_pytest             dbm                 nis                 tabnanny\n",
      "_random             dbus                nltk                tarfile\n",
      "_sha1               debconf             nntplib             tbb\n",
      "_sha256             decimal             notebook            telnetlib\n",
      "_sha512             decorator           ntpath              tempfile\n",
      "_signal             defusedxml          nturl2path          tenacity\n",
      "_sitebuiltins       difflib             numba               tensorboard\n",
      "_socket             dill                numbers             tensorflow\n",
      "_sqlite3            dis                 numpy               tensorflow_core\n",
      "_sre                distro              oauth2client        tensorflow_datasets\n",
      "_ssl                distutils           oauthlib            tensorflow_estimator\n",
      "_stat               docker              opcode              tensorflow_hub\n",
      "_string             docs                operator            tensorflow_io\n",
      "_strptime           doctest             opt_einsum          tensorflow_metadata\n",
      "_struct             dot_parser          optparse            tensorflow_serving\n",
      "_symtable           dummy_threading     os                  termcolor\n",
      "_sysconfigdata      easy_install        ossaudiodev         terminado\n",
      "_sysconfigdata_m    email               packaging           termios\n",
      "_testbuffer         encodings           pandas              test\n",
      "_testcapi           entrypoints         pandas_profiling    testpath\n",
      "_testimportmultiple enum                pandocfilters       tests\n",
      "_testmultiphase     errno               papermill           textwrap\n",
      "_thread             fairing             parser              textwrap3\n",
      "_threading_local    faulthandler        parso               tf2_0_baseline_w_bert\n",
      "_tkinter            fcntl               past                this\n",
      "_tracemalloc        filecmp             pasta               threading\n",
      "_warnings           fileinput           pathlib             time\n",
      "_weakref            fnmatch             pathlib2            timeit\n",
      "_weakrefset         formatter           pdb                 tkinter\n",
      "abc                 fpectl              pexpect             token\n",
      "absl                fractions           phik                tokenize\n",
      "aifc                fsspec              pickle              tornado\n",
      "ansiwrap            ftplib              pickleshare         tqdm\n",
      "antigravity         functools           pickletools         trace\n",
      "apiclient           future              pip                 traceback\n",
      "apt                 gast                pipes               tracemalloc\n",
      "apt_inst            gc                  pkg_resources       traitlets\n",
      "apt_pkg             gcsfs               pkgutil             tty\n",
      "aptsources          genericpath         platform            turtle\n",
      "argparse            getopt              plistlib            typed_ast\n",
      "array               getpass             plotly              types\n",
      "arrow               gettext             plotlywidget        typing\n",
      "ast                 gi                  pluggy              unicodedata\n",
      "astor               git                 poplib              unittest\n",
      "astroid             gitdb               posix               uritemplate\n",
      "astropy             glob                posixpath           urllib\n",
      "asynchat            google_auth_httplib2 poyo                urllib3\n",
      "asyncio             google_auth_oauthlib pprint              uu\n",
      "asyncore            google_compute_engine prettytable         uuid\n",
      "atexit              googleapiclient     profile             venv\n",
      "atomicwrites        grp                 prometheus_client   virtualenv\n",
      "attr                grpc                promise             virtualenv_support\n",
      "audioop             gzip                prompt_toolkit      warnings\n",
      "autoreload          h5py                pstats              wave\n",
      "backcall            hashlib             psutil              wcwidth\n",
      "backports           heapq               pty                 weakref\n",
      "base64              hmac                ptyprocess          webbrowser\n",
      "bcolz               html                pvectorc            webencodings\n",
      "bdb                 html5lib            pwd                 websocket\n",
      "binaryornot         htmlmin             py                  werkzeug\n",
      "binascii            http                py_compile          wheel\n",
      "binhex              httplib2            pyarrow             whichcraft\n",
      "bisect              idlelib             pyasn1              widgetsnbextension\n",
      "bleach              idna                pyasn1_modules      witwidget\n",
      "brain_argparse      imageio             pyclbr              wrapt\n",
      "brain_attrs         imaplib             pycurl              wsgiref\n",
      "brain_builtin_inference imghdr              pydoc               xdg\n",
      "brain_collections   imp                 pydoc_data          xdrlib\n",
      "brain_crypt         importlib           pydot               xml\n",
      "brain_curses        importlib_metadata  pyexpat             xmlrpc\n",
      "brain_dataclasses   inspect             pygments            xxlimited\n",
      "brain_dateutil      io                  pygtkcompat         xxsubtype\n",
      "brain_fstrings      ipaddress           pylab               yaml\n",
      "brain_functools     ipykernel           pylint              zipapp\n",
      "brain_gi            ipykernel_launcher  pyparsing           zipfile\n",
      "brain_hashlib       ipython_genutils    pyrsistent          zipimport\n",
      "brain_http          ipywidgets          pytest              zipp\n",
      "brain_io            isort               pytest_pylint       zlib\n",
      "brain_mechanize     itertools           pytz                zmq\n",
      "brain_multiprocessing jedi                pywt                \n",
      "brain_namedtuple_enum jinja2              qtconsole           \n",
      "brain_nose          jinja2_time         queue               \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose name or summary contain the string \"spam\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(\"modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./.cache/pip/wheels/fb/f8/47/09700d9a19cbcbf0b7a3130690b75c0d6ff80fbda0b1774c7c/bokeh-1.4.0-cp35-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.5/site-packages (from bokeh) (1.15.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.5/dist-packages (from bokeh) (2.10.3)\n",
      "Collecting pillow>=4.0\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/42/fdaf9b53942b103462db3d843c5bc3eb660f9b2e58419ebc99ed87d93dd2/Pillow-7.0.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.5/dist-packages (from bokeh) (5.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.5/dist-packages (from bokeh) (19.2)\n",
      "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.5/dist-packages (from bokeh) (5.1.1)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.5/dist-packages (from bokeh) (1.13.0)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python3.5/dist-packages (from numpy>=1.7.1->bokeh) (1.0.1.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.5/dist-packages (from numpy>=1.7.1->bokeh) (2019.0)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.5/dist-packages (from numpy>=1.7.1->bokeh) (2019.0)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.5/dist-packages (from numpy>=1.7.1->bokeh) (1.0.6)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python3.5/dist-packages (from numpy>=1.7.1->bokeh) (2020.0.133)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.5/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.5/dist-packages (from packaging>=16.8->bokeh) (2.4.5)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python3.5/dist-packages (from mkl-random->numpy>=1.7.1->bokeh) (1.15.1)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.5/dist-packages (from tbb4py->numpy>=1.7.1->bokeh) (2019.0)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.5/dist-packages (from mkl->numpy>=1.7.1->bokeh) (2020.0.133)\n",
      "Installing collected packages: pillow, bokeh\n",
      "\u001b[33m  WARNING: The script bokeh is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed bokeh-1.4.0 pillow-7.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95f6e1395bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "from bokeh.models import Panel, Tabs\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: conda: not found\n"
     ]
    }
   ],
   "source": [
    "!conda install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lightgbm as lgb\n",
    "import plotly.figure_factory as ff\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\t  simplified-nq-train.jsonl  tutorials\n",
      "simplified-nq-test.jsonl  tf2_0_baseline_w_bert.py   Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_path(path, sample= True, chunksize = 30000):\n",
    "    if sample == True:\n",
    "        df =[]\n",
    "        with open(path, 'rt') as reader:\n",
    "            for i in range(chunksize):\n",
    "                df.append(json.loads(reader.readline()))\n",
    "        \n",
    "        df = pd.DataFrame(df)\n",
    "        print(\"Our sampled dataset have {} rows & {} columns\".format(df.shape[0], df.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        df = pd.read_json(path, orient= 'records', lines= True)\n",
    "        print(\"Our dataset have {} rows & {} columns\".format(df.shape[0], df.shape[1]))\n",
    "    \n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our sampled dataset have 30000 rows & 6 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_text</th>\n",
       "      <th>document_url</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_answer_candidates</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'short_answers': [{'end_token': 1969, 'start...</td>\n",
       "      <td>Email marketing - Wikipedia &lt;H1&gt; Email marketi...</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Em...</td>\n",
       "      <td>5655493461695504401</td>\n",
       "      <td>[{'end_token': 170, 'start_token': 14, 'top_le...</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'short_answers': [{'end_token': 215, 'start_...</td>\n",
       "      <td>The Mother ( How I Met Your Mother ) - wikiped...</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>5328212470870865242</td>\n",
       "      <td>[{'end_token': 212, 'start_token': 28, 'top_le...</td>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'short_answers': [], 'annotation_id': 105271...</td>\n",
       "      <td>Human fertilization - wikipedia &lt;H1&gt; Human fer...</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Hu...</td>\n",
       "      <td>4435104480114867852</td>\n",
       "      <td>[{'end_token': 225, 'start_token': 14, 'top_le...</td>\n",
       "      <td>what type of fertilisation takes place in humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'short_answers': [{'end_token': 514, 'start_...</td>\n",
       "      <td>List of National Football League career quarte...</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Li...</td>\n",
       "      <td>5289242154789678439</td>\n",
       "      <td>[{'end_token': 469, 'start_token': 28, 'top_le...</td>\n",
       "      <td>who had the most wins in the nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'short_answers': [], 'annotation_id': 110385...</td>\n",
       "      <td>Roanoke Colony - wikipedia &lt;H1&gt; Roanoke Colony...</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Ro...</td>\n",
       "      <td>5489863933082811018</td>\n",
       "      <td>[{'end_token': 88, 'start_token': 32, 'top_lev...</td>\n",
       "      <td>what happened to the lost settlement of roanoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations  \\\n",
       "0  [{'short_answers': [{'end_token': 1969, 'start...   \n",
       "1  [{'short_answers': [{'end_token': 215, 'start_...   \n",
       "2  [{'short_answers': [], 'annotation_id': 105271...   \n",
       "3  [{'short_answers': [{'end_token': 514, 'start_...   \n",
       "4  [{'short_answers': [], 'annotation_id': 110385...   \n",
       "\n",
       "                                       document_text  \\\n",
       "0  Email marketing - Wikipedia <H1> Email marketi...   \n",
       "1  The Mother ( How I Met Your Mother ) - wikiped...   \n",
       "2  Human fertilization - wikipedia <H1> Human fer...   \n",
       "3  List of National Football League career quarte...   \n",
       "4  Roanoke Colony - wikipedia <H1> Roanoke Colony...   \n",
       "\n",
       "                                        document_url           example_id  \\\n",
       "0  https://en.wikipedia.org//w/index.php?title=Em...  5655493461695504401   \n",
       "1  https://en.wikipedia.org//w/index.php?title=Th...  5328212470870865242   \n",
       "2  https://en.wikipedia.org//w/index.php?title=Hu...  4435104480114867852   \n",
       "3  https://en.wikipedia.org//w/index.php?title=Li...  5289242154789678439   \n",
       "4  https://en.wikipedia.org//w/index.php?title=Ro...  5489863933082811018   \n",
       "\n",
       "                              long_answer_candidates  \\\n",
       "0  [{'end_token': 170, 'start_token': 14, 'top_le...   \n",
       "1  [{'end_token': 212, 'start_token': 28, 'top_le...   \n",
       "2  [{'end_token': 225, 'start_token': 14, 'top_le...   \n",
       "3  [{'end_token': 469, 'start_token': 28, 'top_le...   \n",
       "4  [{'end_token': 88, 'start_token': 32, 'top_lev...   \n",
       "\n",
       "                                       question_text  \n",
       "0  which is the most common use of opt-in e-mail ...  \n",
       "1            how i.met your mother who is the mother  \n",
       "2   what type of fertilisation takes place in humans  \n",
       "3                   who had the most wins in the nfl  \n",
       "4    what happened to the lost settlement of roanoke  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = read_path(\"simplified-nq-train.jsonl\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annotation_id': 593165450220027640,\n",
       "  'long_answer': {'candidate_index': 54,\n",
       "   'end_token': 2019,\n",
       "   'start_token': 1952},\n",
       "  'short_answers': [{'end_token': 1969, 'start_token': 1960}],\n",
       "  'yes_no_answer': 'NONE'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end_token': 170, 'start_token': 14, 'top_level': True},\n",
       " {'end_token': 169, 'start_token': 15, 'top_level': False},\n",
       " {'end_token': 103, 'start_token': 52, 'top_level': False},\n",
       " {'end_token': 102, 'start_token': 53, 'top_level': False},\n",
       " {'end_token': 156, 'start_token': 103, 'top_level': False}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.long_answer_candidates[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which is the most common use of opt-in e-mail marketing'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0, 'question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text_0 = train.loc[0, 'document_text'].split()\n",
    "annotations_0 = train.annotations[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our question is :  which is the most common use of opt-in e-mail marketing\n",
      "Our short answer is :  a newsletter sent to an advertising firm 's customers\n",
      "Our long answer is :  <P> A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter . </P>\n"
     ]
    }
   ],
   "source": [
    "print('Our question is : ', train.loc[0, 'question_text'])\n",
    "print('Our short answer is : ', \" \".join(document_text_0[annotations_0['short_answers'][0]['start_token']:annotations_0['short_answers'][0]['end_token']]))\n",
    "print('Our long answer is : ', \" \".join(document_text_0[annotations_0['long_answer']['start_token']:annotations_0['long_answer']['end_token']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
