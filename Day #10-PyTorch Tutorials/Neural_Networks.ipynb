{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFBAPYaGQDNNtsLSLZ0fcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb7df56c9447457b93072753c8858519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1dcfb90a864444e857e5bec58c04e53",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23002964755d4e17b8620556bd89a97e",
              "IPY_MODEL_de4f5705dbe14073aa189472fe5f048e"
            ]
          }
        },
        "b1dcfb90a864444e857e5bec58c04e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23002964755d4e17b8620556bd89a97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fa73d56a43e4f58ba86bdc9e44e5d36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a10aa1315829469cbb0b0c2d913083ef"
          }
        },
        "de4f5705dbe14073aa189472fe5f048e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83ee12a039ff45588a6b958b03c68ed0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 14621620.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce5b48a2c51647b6a28d1b5f68bb1238"
          }
        },
        "7fa73d56a43e4f58ba86bdc9e44e5d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a10aa1315829469cbb0b0c2d913083ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83ee12a039ff45588a6b958b03c68ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce5b48a2c51647b6a28d1b5f68bb1238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyprince999/100-Days-Of-ML/blob/master/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnz8beJPC_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijbC3ufoVLm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa07MuOEXQ_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "75ee3704-15d5-416d-8b5c-7347844d3757"
      },
      "source": [
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_htTfVRXUUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4561f75-0965-41ce-aea7-64f0b0987c2c"
      },
      "source": [
        "params = list(net.parameters()) # learnable parameters of the model\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK5nNaA4Xg78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7972b711-3097-4e5e-987d-4b25e2dae580"
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0962, -0.1044, -0.0781, -0.0681,  0.0040,  0.0912, -0.0790, -0.0209,\n",
            "         -0.1435,  0.0150]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pabAGXTKXraD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad() # zero-fy all the gradients\n",
        "\n",
        "out.backward(torch.randn(1, 10)) # populate all bckward prop parameters with random weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g313jyNdYRAe",
        "colab_type": "text"
      },
      "source": [
        "torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
        "\n",
        "For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
        "\n",
        "If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6PgKsAYG1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eed71c2-6b5d-4179-a876-f0ac2247a4ca"
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6882, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPVgLstUev_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "156683dd-fd94-4a68-f24f-9635a8d6270d"
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7fc0f74d3b70>\n",
            "<AddmmBackward object at 0x7fc0f74d3b00>\n",
            "<AccumulateGrad object at 0x7fc0f74d3b70>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6uu9CtMfG6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a5c307b6-397e-4039-c93d-8320ca143e02"
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0099, -0.0150, -0.0025, -0.0073, -0.0037,  0.0086])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jPfZHCfTbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01 # Updating the weights using SGD - Stochastic Gradient descent \n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLe9188BfmCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3fced03-5f52-4d58-8352-6e78779efda9"
      },
      "source": [
        "for f in net.parameters():\n",
        "  print(f)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-0.0403, -0.2509,  0.2039],\n",
            "          [ 0.2695,  0.2875,  0.1314],\n",
            "          [ 0.0495, -0.1852,  0.0204]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0088, -0.2980,  0.1891],\n",
            "          [-0.2994, -0.1509,  0.2161],\n",
            "          [-0.2391, -0.2419,  0.2981]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2011,  0.1321,  0.2517],\n",
            "          [ 0.0253, -0.2289,  0.0757],\n",
            "          [-0.2415, -0.0801, -0.1236]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1038,  0.0831,  0.3121],\n",
            "          [-0.3009,  0.1306, -0.1773],\n",
            "          [-0.2855,  0.0431, -0.1962]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1103, -0.0521, -0.1923],\n",
            "          [-0.1159, -0.1225,  0.2292],\n",
            "          [-0.2351,  0.0835,  0.2807]]],\n",
            "\n",
            "\n",
            "        [[[-0.2103,  0.0991,  0.2963],\n",
            "          [-0.1925,  0.2499, -0.2745],\n",
            "          [-0.2112,  0.0464,  0.2388]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2900, -0.0019, -0.0413, -0.3240, -0.2606, -0.0230],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[-1.1370e-01, -8.8005e-02, -5.8358e-02],\n",
            "          [ 1.3507e-01, -1.0970e-01,  9.3921e-03],\n",
            "          [ 1.1464e-01, -1.2240e-01,  1.6862e-03]],\n",
            "\n",
            "         [[ 3.1892e-02, -1.4791e-02, -2.1961e-02],\n",
            "          [ 2.5598e-02,  1.1046e-01,  1.1828e-01],\n",
            "          [-3.6155e-02,  1.7643e-02,  6.3168e-02]],\n",
            "\n",
            "         [[-5.8742e-02, -1.5839e-02,  1.8207e-02],\n",
            "          [-7.7938e-02, -3.1249e-02,  1.1339e-01],\n",
            "          [ 6.0410e-02, -4.2613e-02,  1.3108e-01]],\n",
            "\n",
            "         [[ 7.8950e-03,  2.9314e-02, -3.0825e-03],\n",
            "          [ 1.1406e-01,  6.1847e-02,  1.5440e-02],\n",
            "          [-3.4592e-02,  5.3051e-02, -1.2390e-01]],\n",
            "\n",
            "         [[ 1.1221e-01, -5.2743e-02,  8.8044e-02],\n",
            "          [ 1.1031e-01, -9.1340e-02, -2.0644e-02],\n",
            "          [ 3.6473e-02, -1.0517e-01,  4.6069e-02]],\n",
            "\n",
            "         [[-1.0766e-01,  4.5160e-02,  1.1309e-01],\n",
            "          [-8.2306e-02, -1.2677e-01,  7.3743e-03],\n",
            "          [ 1.7743e-02,  1.2692e-02,  7.4698e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2118e-02, -1.1546e-01,  3.4630e-02],\n",
            "          [ 6.5301e-02,  4.0847e-02,  1.2108e-01],\n",
            "          [ 4.4220e-02,  3.3766e-03,  8.7510e-02]],\n",
            "\n",
            "         [[-1.3484e-02, -6.1854e-02,  6.6687e-02],\n",
            "          [-5.9343e-03,  4.9554e-02, -2.1458e-02],\n",
            "          [ 3.3232e-02,  6.3952e-02, -1.3208e-01]],\n",
            "\n",
            "         [[-5.3824e-02, -5.3190e-02, -4.6999e-03],\n",
            "          [ 8.6904e-02, -6.3670e-03,  1.2497e-01],\n",
            "          [ 8.7000e-02, -1.1964e-02, -9.5765e-02]],\n",
            "\n",
            "         [[ 8.9884e-02,  9.6875e-02,  1.3172e-01],\n",
            "          [ 7.5817e-02,  7.4762e-02,  7.5606e-02],\n",
            "          [ 3.5176e-02, -7.3934e-02,  7.1015e-04]],\n",
            "\n",
            "         [[-1.2401e-01, -1.7954e-02, -7.5132e-02],\n",
            "          [ 4.6745e-02, -1.3163e-01,  6.3178e-02],\n",
            "          [-7.2762e-02, -7.2941e-02,  7.2435e-02]],\n",
            "\n",
            "         [[-1.2305e-01,  9.3350e-02, -3.4036e-03],\n",
            "          [ 2.5579e-02,  2.6816e-02,  1.2015e-02],\n",
            "          [-3.4537e-02,  1.0938e-02, -1.2798e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5096e-02,  9.9368e-03, -7.3410e-02],\n",
            "          [-4.6353e-02,  9.9705e-03,  4.9895e-02],\n",
            "          [ 6.1703e-02, -7.1693e-02, -5.4595e-02]],\n",
            "\n",
            "         [[-5.0350e-02,  9.7532e-04, -4.1769e-03],\n",
            "          [ 1.1527e-01,  7.5421e-02, -8.8626e-02],\n",
            "          [ 1.0747e-01, -5.0023e-02,  8.8740e-02]],\n",
            "\n",
            "         [[-3.5854e-02,  1.3586e-02,  5.3400e-02],\n",
            "          [ 1.2734e-01, -6.0810e-03,  6.1755e-03],\n",
            "          [-4.5973e-02, -2.0934e-02, -7.9225e-02]],\n",
            "\n",
            "         [[ 5.3980e-03, -5.6272e-02, -1.2567e-01],\n",
            "          [-7.3622e-02, -1.1415e-01,  2.7224e-02],\n",
            "          [ 1.2130e-01, -5.4887e-02,  2.2872e-02]],\n",
            "\n",
            "         [[ 1.1527e-01,  2.5931e-03,  1.2237e-02],\n",
            "          [-1.1639e-01, -9.5983e-02, -1.0613e-01],\n",
            "          [-1.0079e-01, -8.5021e-02,  4.6265e-03]],\n",
            "\n",
            "         [[ 2.4614e-02,  1.2554e-01, -6.1488e-02],\n",
            "          [ 1.1972e-01,  4.4258e-02,  7.1419e-02],\n",
            "          [ 2.2741e-02,  1.1916e-01,  1.1808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 9.8225e-02, -5.8892e-02,  2.9121e-02],\n",
            "          [-4.2721e-02, -6.4031e-02,  6.3985e-03],\n",
            "          [-8.1371e-04, -4.8889e-02, -2.3396e-02]],\n",
            "\n",
            "         [[-9.9562e-02, -2.3364e-02,  7.1455e-03],\n",
            "          [ 5.7700e-03,  1.0531e-01, -9.4448e-02],\n",
            "          [ 4.7828e-02, -4.4609e-02,  6.5463e-03]],\n",
            "\n",
            "         [[-7.9763e-02,  1.3134e-01, -1.4185e-02],\n",
            "          [-6.6154e-02,  4.5050e-02, -1.9968e-02],\n",
            "          [-3.4945e-02, -2.0859e-02, -7.9946e-02]],\n",
            "\n",
            "         [[-9.4194e-02,  8.7171e-03,  1.9585e-02],\n",
            "          [-1.2654e-01, -9.2716e-03, -1.4691e-02],\n",
            "          [-6.6806e-04,  1.0921e-01, -5.2151e-02]],\n",
            "\n",
            "         [[ 1.2007e-01,  1.1438e-02,  4.1130e-03],\n",
            "          [ 1.0386e-01, -1.2496e-01,  3.9878e-02],\n",
            "          [-1.0502e-01,  1.0054e-01, -4.3228e-02]],\n",
            "\n",
            "         [[-1.2833e-02,  8.9624e-02, -7.6777e-02],\n",
            "          [ 1.2744e-01,  1.2431e-01, -5.1881e-02],\n",
            "          [-9.2704e-02,  2.3648e-02, -1.1259e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.2030e-02,  5.8179e-02,  5.4538e-02],\n",
            "          [-4.2816e-02,  1.3540e-01, -2.8074e-02],\n",
            "          [-1.2791e-01, -8.7834e-02, -6.7919e-04]],\n",
            "\n",
            "         [[ 8.3375e-02, -1.3167e-01,  1.1406e-01],\n",
            "          [ 2.8828e-02, -9.5472e-02,  6.4929e-02],\n",
            "          [ 8.2833e-02,  7.7155e-02,  7.2566e-02]],\n",
            "\n",
            "         [[-4.8133e-02, -3.5575e-02,  1.0592e-01],\n",
            "          [ 6.7838e-02,  6.9274e-03,  5.0738e-02],\n",
            "          [ 5.0981e-02,  3.5278e-02,  8.2870e-02]],\n",
            "\n",
            "         [[-5.2550e-02, -1.1953e-01, -8.6270e-02],\n",
            "          [-3.6988e-02, -2.3870e-02, -7.3915e-02],\n",
            "          [-1.3138e-03, -1.2158e-01,  1.9957e-03]],\n",
            "\n",
            "         [[-1.4787e-02,  1.4577e-02, -4.1715e-02],\n",
            "          [ 2.7556e-02, -8.5298e-02, -7.6078e-02],\n",
            "          [-3.5111e-02,  1.5477e-02,  8.2075e-02]],\n",
            "\n",
            "         [[-5.5154e-02, -1.1496e-01,  9.7660e-02],\n",
            "          [-1.3583e-01,  1.0963e-01,  6.9879e-02],\n",
            "          [-3.7534e-02, -1.0604e-01, -9.0636e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2108e-02, -5.6219e-03,  3.0114e-02],\n",
            "          [ 3.6444e-02,  1.2806e-02, -9.1236e-02],\n",
            "          [ 3.1658e-02, -1.3493e-01, -1.1298e-01]],\n",
            "\n",
            "         [[ 8.3177e-02,  1.0276e-01, -9.3968e-02],\n",
            "          [ 1.0261e-01, -9.1988e-02, -2.2021e-02],\n",
            "          [-1.0332e-01,  6.5623e-02, -3.9750e-02]],\n",
            "\n",
            "         [[-8.1879e-03, -6.5990e-02,  1.2582e-01],\n",
            "          [-7.0252e-02,  1.0622e-01, -1.9924e-02],\n",
            "          [ 9.7547e-02, -1.0650e-01, -8.9460e-04]],\n",
            "\n",
            "         [[ 2.8721e-02, -1.1853e-01, -1.1601e-01],\n",
            "          [-1.3334e-01,  5.1580e-02, -9.8668e-02],\n",
            "          [-1.2186e-01, -2.0070e-02,  7.4522e-02]],\n",
            "\n",
            "         [[-6.3324e-02,  1.0138e-01,  9.6508e-02],\n",
            "          [ 5.5869e-02,  4.0614e-02,  2.6636e-02],\n",
            "          [ 8.5120e-02,  5.6384e-02,  1.1820e-01]],\n",
            "\n",
            "         [[-6.8670e-02, -2.0394e-02, -1.9568e-02],\n",
            "          [-1.2455e-01,  7.7632e-02, -1.3171e-01],\n",
            "          [ 8.6401e-02, -4.4074e-02, -1.4837e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2775e-03, -9.2354e-02,  2.2598e-02],\n",
            "          [ 6.7038e-02, -2.2749e-04, -1.6260e-02],\n",
            "          [ 4.1194e-02, -3.8895e-02,  6.5301e-02]],\n",
            "\n",
            "         [[ 5.2882e-02,  6.2920e-02,  2.0462e-02],\n",
            "          [-6.4145e-02, -1.3367e-01, -2.0739e-02],\n",
            "          [-1.2991e-01,  5.9423e-02,  1.1924e-01]],\n",
            "\n",
            "         [[ 1.1402e-02, -5.9246e-02, -3.8551e-02],\n",
            "          [ 1.0431e-02,  4.4584e-02, -5.3941e-02],\n",
            "          [-5.0577e-02,  1.3069e-01,  1.1612e-01]],\n",
            "\n",
            "         [[ 6.3625e-02,  9.3542e-02, -3.7618e-02],\n",
            "          [ 6.7897e-02, -2.3882e-02, -3.4408e-02],\n",
            "          [-1.6100e-02, -4.3441e-03,  5.0260e-02]],\n",
            "\n",
            "         [[-4.5500e-02,  8.9156e-02,  3.9407e-02],\n",
            "          [ 1.1503e-01,  1.3191e-01, -9.2115e-03],\n",
            "          [-1.2939e-01,  7.9125e-02,  1.0004e-01]],\n",
            "\n",
            "         [[-7.1420e-02, -3.9182e-02, -1.1572e-02],\n",
            "          [ 8.5293e-02, -3.5632e-02, -1.7555e-02],\n",
            "          [ 9.2901e-02, -5.2902e-02, -4.8146e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1156e-01,  5.2922e-02,  7.8287e-02],\n",
            "          [ 6.3622e-02, -5.2673e-02,  5.9791e-02],\n",
            "          [-1.0162e-01,  1.1711e-01,  1.0791e-01]],\n",
            "\n",
            "         [[ 8.0878e-02, -1.9035e-02, -6.8980e-02],\n",
            "          [-1.3544e-01, -1.1403e-01,  9.1361e-02],\n",
            "          [-3.4647e-02,  1.2139e-01,  4.3031e-02]],\n",
            "\n",
            "         [[ 4.4606e-02, -6.8497e-03, -7.2079e-02],\n",
            "          [ 3.3899e-02, -6.7371e-02,  7.8274e-02],\n",
            "          [ 1.5058e-02,  1.0128e-01,  9.3147e-02]],\n",
            "\n",
            "         [[ 6.6322e-02, -2.0349e-03,  6.3986e-02],\n",
            "          [ 5.5899e-02, -1.1587e-01,  6.5096e-03],\n",
            "          [-1.5853e-02,  4.7482e-02,  7.3231e-03]],\n",
            "\n",
            "         [[ 8.5338e-02, -2.3719e-02,  8.9461e-02],\n",
            "          [ 6.4758e-04, -1.0638e-02, -6.1429e-03],\n",
            "          [ 4.7360e-02,  1.3394e-01,  1.3104e-01]],\n",
            "\n",
            "         [[-9.1591e-02, -1.1352e-01, -2.6039e-02],\n",
            "          [ 1.1401e-01, -1.1873e-01, -4.0806e-02],\n",
            "          [ 8.2977e-02,  2.7134e-02,  1.2524e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3404e-01,  1.2229e-02,  1.7233e-02],\n",
            "          [ 1.9491e-02,  6.6329e-02,  8.3059e-02],\n",
            "          [-2.2837e-02,  2.7290e-02,  8.6159e-02]],\n",
            "\n",
            "         [[-5.8286e-02,  1.1955e-01,  1.0595e-01],\n",
            "          [-4.7249e-02, -2.7015e-02, -1.9432e-02],\n",
            "          [ 1.2944e-01,  1.2938e-01, -1.1275e-02]],\n",
            "\n",
            "         [[-1.3576e-01, -6.7584e-02, -9.5512e-02],\n",
            "          [ 1.1493e-01,  9.8379e-02, -5.2878e-02],\n",
            "          [ 9.4681e-03,  1.3379e-01,  8.8214e-02]],\n",
            "\n",
            "         [[ 7.3389e-02,  1.1265e-02, -3.3850e-02],\n",
            "          [ 1.0207e-01,  1.2006e-01,  9.1871e-02],\n",
            "          [-1.3031e-01, -1.1071e-01,  1.1652e-02]],\n",
            "\n",
            "         [[ 3.4169e-02,  1.1197e-01, -4.1560e-02],\n",
            "          [ 6.9913e-02, -8.1032e-02, -6.1079e-02],\n",
            "          [-1.1244e-01,  1.2100e-01,  1.1764e-01]],\n",
            "\n",
            "         [[ 8.9464e-02,  6.8136e-02, -9.8151e-02],\n",
            "          [-2.0173e-02, -9.4614e-03,  5.3887e-02],\n",
            "          [-1.0426e-01, -2.4436e-02,  8.0107e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0301e-02,  1.2920e-01, -5.2147e-02],\n",
            "          [ 8.4496e-02, -1.2355e-01,  1.0674e-01],\n",
            "          [ 7.0153e-03,  2.9162e-03,  9.9491e-02]],\n",
            "\n",
            "         [[ 1.1386e-01, -8.9721e-02, -4.4879e-02],\n",
            "          [-3.4102e-02,  1.2353e-01, -3.5971e-02],\n",
            "          [-1.2535e-01,  7.6722e-02,  5.4855e-02]],\n",
            "\n",
            "         [[ 1.3101e-01,  5.8794e-02,  7.4266e-03],\n",
            "          [-1.0232e-01,  1.0719e-01, -6.3422e-03],\n",
            "          [ 1.0061e-01,  6.5181e-02, -3.7590e-03]],\n",
            "\n",
            "         [[ 1.0432e-01, -3.1958e-02,  8.2347e-02],\n",
            "          [ 3.5948e-02, -3.5677e-02,  5.9014e-02],\n",
            "          [-1.1990e-04, -1.0181e-01, -1.1437e-02]],\n",
            "\n",
            "         [[ 1.4224e-02, -3.7106e-02,  1.0589e-02],\n",
            "          [-7.0509e-02, -1.3089e-01, -1.1629e-01],\n",
            "          [-2.2577e-02,  1.8179e-02, -2.1500e-02]],\n",
            "\n",
            "         [[-2.7284e-02, -5.1708e-02,  1.9203e-02],\n",
            "          [ 3.7062e-02, -1.0732e-01,  6.1072e-03],\n",
            "          [ 6.9128e-02,  5.5611e-02, -6.2026e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3183e-01,  1.1194e-01, -9.5482e-02],\n",
            "          [-8.9484e-02,  9.4041e-02, -8.9024e-03],\n",
            "          [ 2.5413e-02, -1.0073e-01,  3.8577e-02]],\n",
            "\n",
            "         [[ 9.2210e-02,  3.1596e-02,  1.3205e-01],\n",
            "          [-1.3492e-01,  7.6409e-02,  1.6860e-02],\n",
            "          [ 3.5227e-02,  1.2274e-01, -1.0186e-01]],\n",
            "\n",
            "         [[-6.9686e-02,  7.5705e-02, -6.5408e-02],\n",
            "          [-2.3123e-02, -5.0597e-02,  1.0429e-01],\n",
            "          [ 1.2281e-01,  5.0059e-02, -9.3705e-03]],\n",
            "\n",
            "         [[ 2.1734e-02,  7.4583e-02,  1.3069e-01],\n",
            "          [-3.7385e-02, -7.3928e-02,  2.8475e-02],\n",
            "          [-1.1792e-01,  3.0856e-02, -9.9723e-02]],\n",
            "\n",
            "         [[-1.2001e-01,  2.3922e-02,  1.0695e-01],\n",
            "          [ 1.0948e-01, -8.7648e-03, -2.8473e-02],\n",
            "          [-1.4856e-02,  8.4040e-02, -1.1088e-01]],\n",
            "\n",
            "         [[ 1.5907e-02,  8.8849e-02,  1.2902e-01],\n",
            "          [ 1.2464e-01, -9.5831e-02, -9.3251e-02],\n",
            "          [-4.0536e-02,  5.2589e-02,  1.0163e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0711e-02, -9.9655e-02,  9.3752e-02],\n",
            "          [ 1.0367e-01, -5.0847e-02,  9.2094e-02],\n",
            "          [-6.7483e-02,  1.0573e-01, -9.5042e-03]],\n",
            "\n",
            "         [[ 4.0637e-02,  2.1376e-02,  1.3388e-01],\n",
            "          [-1.1632e-01, -4.2846e-02, -4.5092e-02],\n",
            "          [ 1.2006e-01,  5.4876e-02, -7.3076e-02]],\n",
            "\n",
            "         [[ 9.8165e-02,  2.5221e-02, -1.2080e-01],\n",
            "          [-1.2395e-01,  4.7817e-02, -3.1982e-03],\n",
            "          [ 1.1779e-01,  4.2427e-02, -1.2241e-01]],\n",
            "\n",
            "         [[ 9.6979e-02,  1.1709e-01, -1.2614e-02],\n",
            "          [-5.8997e-02,  9.3371e-02, -1.3559e-01],\n",
            "          [-9.7630e-02,  5.3230e-02, -7.3556e-02]],\n",
            "\n",
            "         [[ 2.7657e-02, -7.9805e-02,  6.6917e-02],\n",
            "          [ 7.7654e-02, -1.2724e-01, -4.8193e-02],\n",
            "          [-1.3516e-01, -1.0639e-01,  8.5330e-02]],\n",
            "\n",
            "         [[ 9.2911e-02, -1.1546e-02, -2.2396e-02],\n",
            "          [-3.6324e-02, -6.0210e-03,  1.4513e-02],\n",
            "          [-1.1298e-01,  2.6559e-02, -1.0232e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.5105e-03, -3.8751e-02, -2.5944e-02],\n",
            "          [ 1.1696e-01, -7.4409e-02,  1.2794e-01],\n",
            "          [-1.7127e-02,  1.2602e-01,  2.8280e-02]],\n",
            "\n",
            "         [[-1.1342e-01,  1.2105e-01,  3.6929e-02],\n",
            "          [ 1.3117e-01,  1.2521e-01,  6.7360e-02],\n",
            "          [-6.0361e-02, -1.0297e-02, -1.2866e-01]],\n",
            "\n",
            "         [[-7.2923e-02, -2.5642e-02, -5.4641e-02],\n",
            "          [-1.0202e-01,  3.9222e-02, -9.3917e-02],\n",
            "          [ 1.0691e-01, -1.1080e-01,  6.0492e-02]],\n",
            "\n",
            "         [[-8.4417e-02,  6.6696e-02,  7.9129e-02],\n",
            "          [ 3.3277e-02, -6.4999e-04,  8.8535e-02],\n",
            "          [-7.8824e-02, -3.4002e-02,  3.1265e-02]],\n",
            "\n",
            "         [[ 1.0478e-02, -5.4854e-03,  7.5405e-02],\n",
            "          [-1.8024e-02,  9.5280e-02, -1.2626e-01],\n",
            "          [-4.7489e-02,  1.2119e-01, -1.2370e-01]],\n",
            "\n",
            "         [[ 9.0539e-02,  7.7177e-03,  7.2134e-02],\n",
            "          [ 1.2560e-01, -1.1181e-01, -2.0579e-02],\n",
            "          [-8.5873e-02,  4.3858e-02, -6.8128e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.3482e-02,  7.6903e-02,  1.2885e-01],\n",
            "          [ 1.2516e-01, -4.7682e-02, -7.3659e-02],\n",
            "          [ 3.7170e-02,  4.8117e-02, -3.8959e-02]],\n",
            "\n",
            "         [[ 2.2671e-02,  1.8388e-02, -1.4079e-02],\n",
            "          [-3.2709e-02,  2.2379e-02, -5.8524e-02],\n",
            "          [-4.6348e-02, -4.8055e-02,  5.7729e-02]],\n",
            "\n",
            "         [[ 6.9035e-02, -1.2049e-01, -1.2859e-01],\n",
            "          [-1.8935e-02, -2.7720e-02,  3.4803e-02],\n",
            "          [ 1.1046e-01, -4.9593e-02,  1.2181e-02]],\n",
            "\n",
            "         [[ 7.9502e-02,  5.0440e-02,  3.1245e-02],\n",
            "          [-5.6729e-02, -5.6260e-02,  9.5814e-02],\n",
            "          [-2.1954e-02,  1.0441e-01,  2.3664e-02]],\n",
            "\n",
            "         [[-1.2418e-01, -9.3463e-02, -4.7638e-02],\n",
            "          [-3.7539e-02, -1.0040e-01, -6.4190e-02],\n",
            "          [-6.0574e-02, -8.4910e-02,  6.5270e-02]],\n",
            "\n",
            "         [[-1.1222e-01, -1.2654e-01,  1.1740e-01],\n",
            "          [ 1.4588e-02, -5.6708e-02, -1.3942e-02],\n",
            "          [ 2.9090e-02,  1.2259e-01, -1.5787e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6516e-02, -3.0123e-03,  1.1294e-01],\n",
            "          [ 6.5180e-03, -3.6136e-02,  1.2100e-01],\n",
            "          [ 1.0319e-02, -2.3986e-02, -5.6666e-02]],\n",
            "\n",
            "         [[ 1.1784e-01,  8.3020e-02,  6.8024e-02],\n",
            "          [-6.0578e-02,  7.1246e-02,  9.5824e-02],\n",
            "          [-4.1397e-02, -3.5729e-02,  2.1198e-02]],\n",
            "\n",
            "         [[-1.0503e-01,  8.0705e-02, -5.5932e-02],\n",
            "          [ 4.8432e-02,  1.3172e-01, -1.0877e-01],\n",
            "          [ 2.6282e-02,  4.1258e-02,  1.2077e-01]],\n",
            "\n",
            "         [[-1.0336e-02,  3.8775e-02,  4.4693e-02],\n",
            "          [ 7.3352e-02,  1.1174e-01,  1.0935e-02],\n",
            "          [-1.6229e-02, -6.0837e-02,  9.4842e-02]],\n",
            "\n",
            "         [[ 7.2485e-02, -9.3434e-02, -2.0612e-02],\n",
            "          [-9.8393e-02, -4.0343e-02, -8.3586e-02],\n",
            "          [ 3.3803e-02, -6.7654e-02, -6.5371e-02]],\n",
            "\n",
            "         [[-7.6899e-02, -1.1712e-02,  3.9978e-02],\n",
            "          [ 7.8997e-02, -2.4765e-02, -2.1574e-02],\n",
            "          [ 1.1854e-01, -2.2479e-02, -8.8253e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.3769e-02,  1.1073e-01,  1.3236e-01],\n",
            "          [-3.2465e-02, -3.4742e-02, -9.4631e-02],\n",
            "          [ 1.2686e-01, -6.6610e-03,  1.1410e-01]],\n",
            "\n",
            "         [[ 9.9989e-02, -1.2218e-01, -7.3828e-03],\n",
            "          [ 1.2837e-03,  5.5025e-02, -1.2312e-01],\n",
            "          [-2.0390e-03,  3.6292e-02, -1.9301e-02]],\n",
            "\n",
            "         [[ 5.0922e-03, -8.6249e-02,  3.7266e-02],\n",
            "          [ 1.1192e-02,  7.3618e-02,  1.1438e-01],\n",
            "          [ 9.7512e-02, -2.9091e-02, -1.1431e-01]],\n",
            "\n",
            "         [[ 6.1219e-02,  8.9530e-02,  1.1960e-01],\n",
            "          [-8.7630e-02,  5.1885e-02, -5.5781e-02],\n",
            "          [-9.6758e-03, -4.3876e-02,  2.7219e-02]],\n",
            "\n",
            "         [[ 1.3389e-01, -1.3519e-02, -7.1188e-02],\n",
            "          [-1.0723e-02, -1.1247e-01, -5.5465e-02],\n",
            "          [ 1.1302e-01,  1.2101e-01,  9.5208e-02]],\n",
            "\n",
            "         [[-4.7107e-02,  9.3800e-02, -1.0742e-01],\n",
            "          [ 7.9541e-02,  6.9273e-02,  1.2233e-01],\n",
            "          [ 1.1063e-01,  8.0743e-02,  2.1451e-02]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0420,  0.0894, -0.0834, -0.0319,  0.1305,  0.0147, -0.0221,  0.0515,\n",
            "        -0.1104, -0.0704, -0.0603, -0.0217, -0.1160, -0.1022, -0.1064, -0.0449],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0396,  0.0374,  0.0046,  ..., -0.0341, -0.0019, -0.0358],\n",
            "        [ 0.0261,  0.0188,  0.0072,  ..., -0.0366, -0.0359, -0.0377],\n",
            "        [-0.0037,  0.0221,  0.0108,  ...,  0.0090, -0.0040,  0.0063],\n",
            "        ...,\n",
            "        [-0.0310, -0.0220, -0.0146,  ...,  0.0043,  0.0377, -0.0013],\n",
            "        [-0.0100,  0.0271,  0.0204,  ...,  0.0401,  0.0070,  0.0076],\n",
            "        [ 0.0088,  0.0092,  0.0166,  ..., -0.0382, -0.0394,  0.0076]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0218,  0.0210, -0.0193, -0.0311, -0.0398,  0.0293,  0.0054,  0.0017,\n",
            "        -0.0201,  0.0226,  0.0375,  0.0261, -0.0342,  0.0397, -0.0177, -0.0273,\n",
            "        -0.0160,  0.0280,  0.0002, -0.0057,  0.0006,  0.0133, -0.0091, -0.0091,\n",
            "        -0.0217, -0.0318, -0.0055,  0.0159, -0.0393,  0.0294, -0.0321, -0.0342,\n",
            "         0.0265,  0.0143,  0.0320, -0.0398,  0.0343,  0.0017,  0.0266, -0.0171,\n",
            "         0.0388, -0.0267,  0.0004, -0.0403,  0.0295,  0.0012, -0.0265, -0.0389,\n",
            "         0.0261,  0.0281,  0.0300,  0.0133,  0.0001, -0.0289, -0.0240, -0.0097,\n",
            "         0.0106, -0.0077,  0.0108,  0.0273,  0.0243, -0.0003, -0.0368, -0.0031,\n",
            "        -0.0221,  0.0055,  0.0227, -0.0177,  0.0046, -0.0172, -0.0183,  0.0041,\n",
            "         0.0265,  0.0303,  0.0366, -0.0319,  0.0099,  0.0234,  0.0043, -0.0269,\n",
            "        -0.0052, -0.0057, -0.0122,  0.0095, -0.0306,  0.0321, -0.0230,  0.0309,\n",
            "        -0.0271,  0.0066,  0.0377, -0.0324,  0.0133, -0.0334,  0.0337, -0.0071,\n",
            "         0.0322, -0.0126, -0.0347,  0.0414, -0.0305, -0.0347,  0.0181,  0.0097,\n",
            "        -0.0294,  0.0058, -0.0049, -0.0246, -0.0363, -0.0302, -0.0105,  0.0416,\n",
            "        -0.0086, -0.0167,  0.0408,  0.0167,  0.0115,  0.0221, -0.0271,  0.0140],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0818,  0.0017,  0.0857,  ..., -0.0355,  0.0587,  0.0755],\n",
            "        [ 0.0295, -0.0657, -0.0658,  ...,  0.0161, -0.0141,  0.0736],\n",
            "        [ 0.0510, -0.0868,  0.0112,  ...,  0.0353,  0.0433,  0.0024],\n",
            "        ...,\n",
            "        [ 0.0459,  0.0846, -0.0696,  ...,  0.0255,  0.0851, -0.0489],\n",
            "        [-0.0660, -0.0044,  0.0900,  ...,  0.0097, -0.0333, -0.0384],\n",
            "        [-0.0682,  0.0520,  0.0777,  ...,  0.0680, -0.0383, -0.0412]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0249, -0.0815,  0.0549, -0.0865, -0.0024,  0.0496, -0.0780, -0.0182,\n",
            "         0.0301, -0.0047, -0.0015,  0.0723,  0.0430,  0.0169,  0.0703,  0.0031,\n",
            "         0.0570,  0.0560,  0.0889, -0.0698,  0.0086, -0.0700,  0.0545,  0.0889,\n",
            "         0.0831, -0.0399, -0.0492, -0.0681,  0.0064,  0.0576, -0.0243, -0.0913,\n",
            "        -0.0108,  0.0166, -0.0109,  0.0741, -0.0649, -0.0013,  0.0586,  0.0530,\n",
            "         0.0547,  0.0318, -0.0671, -0.0475,  0.0231, -0.0685, -0.0640, -0.0492,\n",
            "        -0.0025,  0.0344,  0.0504, -0.0362,  0.0546, -0.0152, -0.0792,  0.0401,\n",
            "         0.0144,  0.0045, -0.0132,  0.0901,  0.0709, -0.0203,  0.0028, -0.0352,\n",
            "        -0.0399,  0.0413, -0.0720,  0.0609, -0.0691,  0.0332, -0.0432, -0.0818,\n",
            "         0.0543, -0.0536,  0.0630, -0.0027, -0.0783, -0.0814, -0.0414,  0.0881,\n",
            "        -0.0203,  0.0015, -0.0339,  0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0048,  0.0658, -0.0484, -0.0751,  0.0994,  0.0779,  0.0163, -0.0734,\n",
            "          0.0279,  0.0962,  0.1081,  0.0713,  0.0027, -0.0274, -0.0493,  0.0607,\n",
            "         -0.0561, -0.0005, -0.0011,  0.0122,  0.0150, -0.0569, -0.0350,  0.0321,\n",
            "          0.0549,  0.0780,  0.0606,  0.0743,  0.0843,  0.0812, -0.0216,  0.0262,\n",
            "          0.0659, -0.0194, -0.0482,  0.0287, -0.0901, -0.0369, -0.0538,  0.0798,\n",
            "          0.0227,  0.0204, -0.0003, -0.0409,  0.0789, -0.0668,  0.0103, -0.1034,\n",
            "          0.0296, -0.0407,  0.0406,  0.0321,  0.0079,  0.0355,  0.0371, -0.0707,\n",
            "          0.0306, -0.0678,  0.0436,  0.0714, -0.0682,  0.0425,  0.0015,  0.0206,\n",
            "          0.0507,  0.0246, -0.0068, -0.0661,  0.0411,  0.1072,  0.1000, -0.0490,\n",
            "          0.1009,  0.0590,  0.0793,  0.1082, -0.0550,  0.0257,  0.0162, -0.0621,\n",
            "         -0.0297,  0.0888, -0.0266, -0.0034],\n",
            "        [ 0.0880, -0.0105, -0.0628, -0.0339,  0.0615, -0.0571, -0.0714,  0.1018,\n",
            "          0.1072,  0.1030, -0.0801, -0.0489,  0.0702, -0.0650,  0.0013,  0.0918,\n",
            "         -0.0176, -0.0562, -0.0380,  0.0915,  0.0665,  0.0278, -0.0573,  0.0450,\n",
            "          0.0243,  0.0010, -0.1045, -0.0499,  0.0430,  0.0606,  0.0658,  0.0294,\n",
            "         -0.0239,  0.0411,  0.0566,  0.0246,  0.0225, -0.1091, -0.0515, -0.0864,\n",
            "          0.0416,  0.0090,  0.0312,  0.0420, -0.0353,  0.0541, -0.0347, -0.0350,\n",
            "          0.0680, -0.0668,  0.0115,  0.0930, -0.0609, -0.0268,  0.0099, -0.0738,\n",
            "         -0.1078, -0.0169, -0.0214, -0.0865, -0.0251, -0.1035,  0.0562, -0.0628,\n",
            "          0.0468,  0.1053, -0.0897, -0.0799, -0.0387,  0.0125, -0.0153, -0.0923,\n",
            "         -0.0454, -0.0478,  0.1014,  0.0332,  0.0371,  0.0819,  0.0956, -0.0055,\n",
            "          0.0120, -0.0571, -0.0598, -0.0391],\n",
            "        [-0.0358, -0.0409, -0.0623, -0.0688,  0.0184,  0.0836,  0.1078, -0.0360,\n",
            "          0.0698,  0.0854,  0.0776,  0.0544,  0.1025,  0.0758, -0.0991,  0.0813,\n",
            "         -0.0844, -0.0095,  0.0018,  0.0899, -0.0833, -0.0381,  0.0380, -0.0070,\n",
            "         -0.0344, -0.0759, -0.0530, -0.0642,  0.0283, -0.0294,  0.0382, -0.0348,\n",
            "          0.0008,  0.0072,  0.0830, -0.0218,  0.0518, -0.0081, -0.1015,  0.0475,\n",
            "         -0.0113,  0.1044,  0.0426,  0.0744,  0.0609, -0.0610, -0.0225, -0.0720,\n",
            "         -0.0645, -0.0669,  0.0866, -0.0972,  0.0843, -0.0116, -0.0878,  0.0702,\n",
            "         -0.1017, -0.0405,  0.0028,  0.0404, -0.0214, -0.0969,  0.0672, -0.0606,\n",
            "          0.0815,  0.0517,  0.0480,  0.0646, -0.0344,  0.0954, -0.0331,  0.0863,\n",
            "         -0.0429,  0.0281,  0.0385, -0.0650, -0.0696, -0.0607, -0.0065,  0.0697,\n",
            "          0.0802,  0.1025, -0.0648, -0.0339],\n",
            "        [-0.0791, -0.0307, -0.0085,  0.0870, -0.0819,  0.0386, -0.0936,  0.0469,\n",
            "         -0.0480, -0.1002, -0.0894, -0.0747,  0.0334,  0.0321,  0.0091, -0.0483,\n",
            "          0.0672, -0.0006,  0.0756,  0.0562, -0.0402, -0.0464, -0.1065, -0.1052,\n",
            "         -0.0533,  0.0253, -0.0136, -0.0063, -0.0313, -0.0926, -0.0266, -0.0916,\n",
            "          0.0741, -0.0323,  0.1038, -0.0820, -0.0103,  0.0237,  0.0349,  0.1013,\n",
            "          0.1038,  0.0569,  0.1072, -0.0559, -0.0927, -0.0537, -0.0412,  0.1034,\n",
            "         -0.0202, -0.0445, -0.0653, -0.0044, -0.0291,  0.1024,  0.0718,  0.0911,\n",
            "         -0.0237,  0.0591,  0.0569, -0.0329,  0.1077,  0.0190, -0.0404, -0.0349,\n",
            "         -0.0161,  0.0440, -0.0163, -0.0559,  0.0671,  0.0189, -0.0434,  0.0032,\n",
            "         -0.0514,  0.0932,  0.0202, -0.0112,  0.0159, -0.1033, -0.0383, -0.0813,\n",
            "          0.0327,  0.0892, -0.0895, -0.1029],\n",
            "        [ 0.0255, -0.0809, -0.0916, -0.0334,  0.0317,  0.0162,  0.0387, -0.0707,\n",
            "          0.0453, -0.0488, -0.0748,  0.0452, -0.0927,  0.0083, -0.0324, -0.0459,\n",
            "         -0.0559,  0.0311,  0.0908, -0.0799,  0.0820,  0.0900,  0.0998,  0.0129,\n",
            "         -0.0062, -0.0632, -0.0449,  0.0875,  0.0345, -0.0608,  0.0735, -0.0505,\n",
            "         -0.0961, -0.0876,  0.0505, -0.0471,  0.0988, -0.0976, -0.0573,  0.0552,\n",
            "          0.0131, -0.0996, -0.0634, -0.0592,  0.0498,  0.0926,  0.0657,  0.0959,\n",
            "         -0.0731,  0.0713, -0.0531, -0.0733, -0.0782, -0.0744, -0.0142,  0.0236,\n",
            "          0.0248,  0.0390,  0.0848, -0.0665,  0.0584,  0.0846,  0.0724,  0.0301,\n",
            "         -0.0743,  0.0073, -0.0663,  0.0744,  0.0418, -0.0680,  0.0802, -0.0515,\n",
            "          0.0524,  0.0698,  0.0133,  0.0121, -0.0625,  0.0410,  0.0412, -0.0848,\n",
            "          0.0699, -0.0032, -0.1033, -0.0286],\n",
            "        [ 0.0384,  0.0554, -0.0288, -0.0431, -0.0912,  0.0406,  0.0643,  0.0990,\n",
            "         -0.0376,  0.0731, -0.0718, -0.0851,  0.0675,  0.0096,  0.1012,  0.0514,\n",
            "         -0.0817, -0.0079, -0.0109,  0.0670,  0.0781, -0.0739,  0.0351, -0.0618,\n",
            "          0.1044, -0.0304,  0.0343, -0.0814, -0.0625, -0.0457, -0.0829,  0.0458,\n",
            "          0.0141,  0.0338, -0.0649,  0.0135, -0.0468, -0.0388,  0.0850, -0.0511,\n",
            "          0.0661,  0.0268,  0.0967,  0.0842,  0.0678, -0.0787,  0.0925,  0.1016,\n",
            "         -0.0826, -0.0519, -0.0776, -0.0318,  0.0913,  0.0320,  0.0758, -0.1023,\n",
            "         -0.0132, -0.0653,  0.0255,  0.0579,  0.0416,  0.0357,  0.0907,  0.0012,\n",
            "         -0.0488,  0.0565,  0.0557,  0.0980,  0.0508,  0.0962, -0.0123, -0.0295,\n",
            "         -0.1030,  0.0763,  0.0798,  0.0749,  0.0556, -0.0250, -0.0796,  0.0841,\n",
            "         -0.0159, -0.0840, -0.0936, -0.0670],\n",
            "        [ 0.0877,  0.0266, -0.0620, -0.0279,  0.0340, -0.0603,  0.0027,  0.0189,\n",
            "         -0.0015,  0.0952,  0.0408, -0.0402, -0.0044, -0.0290, -0.1075,  0.0575,\n",
            "         -0.1045,  0.0613,  0.0315, -0.0542, -0.1087,  0.0278, -0.0710, -0.0547,\n",
            "         -0.0819,  0.0988, -0.0991,  0.0271,  0.1056,  0.1067, -0.0825, -0.0118,\n",
            "         -0.0792,  0.0650, -0.0708, -0.0420,  0.0353,  0.0972,  0.0919,  0.0065,\n",
            "          0.0434,  0.0834,  0.0792,  0.0858,  0.0428, -0.0569, -0.1035,  0.0007,\n",
            "          0.0372,  0.0631,  0.0861,  0.0140,  0.0153,  0.1009, -0.0762,  0.0144,\n",
            "         -0.0673, -0.0727, -0.0578, -0.0236,  0.0908,  0.0225,  0.0883, -0.0805,\n",
            "         -0.0936,  0.0699,  0.0221,  0.1041, -0.0649, -0.0872, -0.0413,  0.0542,\n",
            "         -0.0535,  0.0786, -0.0416,  0.0879, -0.1049, -0.1045, -0.0177, -0.0377,\n",
            "         -0.0911, -0.0074, -0.1038, -0.0472],\n",
            "        [ 0.0164,  0.0020, -0.0927,  0.0978,  0.0167, -0.0159,  0.0705,  0.0556,\n",
            "          0.0572, -0.0642,  0.0678, -0.0981, -0.0728,  0.0102, -0.0758,  0.0900,\n",
            "          0.0166,  0.0017,  0.0385,  0.0882,  0.0772,  0.0125,  0.0665, -0.0064,\n",
            "         -0.0956,  0.0171,  0.0700, -0.0005,  0.1009, -0.0337, -0.0865, -0.0640,\n",
            "          0.0053,  0.0945, -0.0716, -0.0386, -0.0293, -0.0096, -0.0927,  0.0621,\n",
            "         -0.0755, -0.0765, -0.0279, -0.0662, -0.0563, -0.0478,  0.0707, -0.0942,\n",
            "         -0.1001,  0.0898,  0.0778, -0.0209,  0.0119, -0.0901, -0.1013,  0.0009,\n",
            "         -0.0863,  0.0754,  0.1069,  0.0317, -0.0373,  0.0905,  0.0290,  0.0125,\n",
            "         -0.0222, -0.0572, -0.0034,  0.0730, -0.0057, -0.0564,  0.1050,  0.0399,\n",
            "         -0.0828, -0.0570, -0.0776,  0.0619, -0.0025,  0.0352, -0.0312, -0.0496,\n",
            "          0.0928,  0.0160,  0.0125, -0.0444],\n",
            "        [ 0.0068, -0.0297,  0.0176,  0.0125,  0.0693, -0.0476,  0.0953,  0.0549,\n",
            "          0.0793,  0.0464, -0.0019,  0.0956, -0.0821, -0.1072,  0.0768, -0.0896,\n",
            "         -0.0541, -0.0876, -0.0856,  0.0161,  0.0007,  0.0833,  0.0007,  0.0117,\n",
            "         -0.0717, -0.0411,  0.0517,  0.0194, -0.0967, -0.0176,  0.0784,  0.0335,\n",
            "          0.0031, -0.0983,  0.0891,  0.0772,  0.1038, -0.0573, -0.0571,  0.0316,\n",
            "         -0.0633,  0.0542,  0.0174, -0.0815,  0.0674, -0.1009,  0.0313,  0.0486,\n",
            "          0.0477, -0.0951,  0.0538,  0.0887, -0.0683, -0.0162,  0.0273, -0.0409,\n",
            "         -0.0549,  0.1088, -0.0010,  0.0892,  0.0562,  0.1067, -0.0229, -0.0206,\n",
            "          0.0177,  0.0457, -0.0314, -0.0391, -0.0768,  0.1090, -0.1025, -0.1054,\n",
            "          0.0057,  0.0207, -0.0336,  0.0286, -0.0315,  0.0470,  0.1014, -0.0593,\n",
            "         -0.1021,  0.0760, -0.0580, -0.0886],\n",
            "        [ 0.0447, -0.0106,  0.0283, -0.0264, -0.0798,  0.0050, -0.0348,  0.1017,\n",
            "          0.0693, -0.0175,  0.0551, -0.0797, -0.0401,  0.0999, -0.0230,  0.0578,\n",
            "          0.1061, -0.0005,  0.0954, -0.0830, -0.1044, -0.1040, -0.0957, -0.0214,\n",
            "          0.0076,  0.0457,  0.0896, -0.1031, -0.1054, -0.0394, -0.1064,  0.0062,\n",
            "         -0.1007, -0.0656,  0.0751, -0.0330, -0.0926, -0.0215, -0.0555,  0.0588,\n",
            "         -0.0360,  0.0486,  0.0722, -0.0138,  0.0835,  0.0347, -0.0721, -0.0660,\n",
            "         -0.0038,  0.0874,  0.0695, -0.0819,  0.0573,  0.0318,  0.0833,  0.0790,\n",
            "         -0.0211,  0.0270,  0.0860,  0.0024, -0.0639,  0.0394, -0.0866, -0.0563,\n",
            "         -0.0769, -0.0586,  0.0862,  0.0264,  0.0781,  0.0964, -0.0686,  0.0554,\n",
            "         -0.0459,  0.0790, -0.0452,  0.0967, -0.0535,  0.0428,  0.0215,  0.0302,\n",
            "         -0.0452, -0.0589,  0.0934,  0.0232]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0244, -0.0592, -0.0707, -0.0207, -0.0152,  0.0919, -0.0365, -0.0641,\n",
            "        -0.0881, -0.0279], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SznDA9tVgALg",
        "colab_type": "text"
      },
      "source": [
        "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: torch.optim that implements all these methods. Using it is very simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRn2EzZffpWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6-_iMx-hAO5",
        "colab_type": "text"
      },
      "source": [
        "################################################################################\n",
        "\n",
        "We will now create an image classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sH2l-QvgDB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw95jdm1hN7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "fb7df56c9447457b93072753c8858519",
            "b1dcfb90a864444e857e5bec58c04e53",
            "23002964755d4e17b8620556bd89a97e",
            "de4f5705dbe14073aa189472fe5f048e",
            "7fa73d56a43e4f58ba86bdc9e44e5d36",
            "a10aa1315829469cbb0b0c2d913083ef",
            "83ee12a039ff45588a6b958b03c68ed0",
            "ce5b48a2c51647b6a28d1b5f68bb1238"
          ]
        },
        "outputId": "0da28f95-ff29-43a8-f1bc-a49f6b6aef9e"
      },
      "source": [
        "#The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb7df56c9447457b93072753c8858519",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "300BRPVWhh2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bff666d0-54de-4e01-d299-7f733e9ca928"
      },
      "source": [
        "!ls data/cifar-10-batches-py/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batches.meta  data_batch_2  data_batch_4  readme.html\n",
            "data_batch_1  data_batch_3  data_batch_5  test_batch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPQoCNjvhmtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eD-uK_jh3xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-aWXJV8iBbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "47273a2f-20a0-4936-adfb-b076945774ed"
      },
      "source": [
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWhT+Ae7h4eHRovAPcA8PD48Wxf8Df3wEMStzRfcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "horse  ship  bird plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSbzCvB7iEjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6ac5sZiqsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fBxE2n4jh5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "12b78dda-54ba-4bf2-e227-46b9d8ea0249"
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.215\n",
            "[1,  4000] loss: 1.845\n",
            "[1,  6000] loss: 1.688\n",
            "[1,  8000] loss: 1.606\n",
            "[1, 10000] loss: 1.501\n",
            "[1, 12000] loss: 1.454\n",
            "[2,  2000] loss: 1.377\n",
            "[2,  4000] loss: 1.339\n",
            "[2,  6000] loss: 1.331\n",
            "[2,  8000] loss: 1.280\n",
            "[2, 10000] loss: 1.290\n",
            "[2, 12000] loss: 1.244\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cmOLtdFlAKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the model\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfl6fJ4ZlLs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "4bd80a54-250f-4287-d3ba-9aadd023111f"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxf8HV/T+BepgTjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ray-wa0Blbyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1aee4ec-4c09-4664-d579-e41f170ddcec"
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RZT9I6gljI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_yal6EYlpgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8b9c249-e52b-4378-e81b-dafff4b5b3a8"
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:    cat  ship  ship plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT0kl7yHlx1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "435564d5-07e3-4dff-a080-35e29088c91c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 56 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rltbLN9WmEmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f80e0ada-da24-46c9-a480-8408b532ef83"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 67 %\n",
            "Accuracy of   car : 78 %\n",
            "Accuracy of  bird : 38 %\n",
            "Accuracy of   cat : 25 %\n",
            "Accuracy of  deer : 51 %\n",
            "Accuracy of   dog : 39 %\n",
            "Accuracy of  frog : 78 %\n",
            "Accuracy of horse : 63 %\n",
            "Accuracy of  ship : 67 %\n",
            "Accuracy of truck : 49 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDwm1pqkmacK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2be54ae-c096-43d8-e6bf-be372d6eb35c"
      },
      "source": [
        "10+2"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXKd1PhPmx-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f777fcea-6ad8-4667-ffb9-da2d345780ac"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXM0elMym5lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e10777ae-26db-4ede-f8fc-b1807a69312a"
      },
      "source": [
        "net.to(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnQg5zmocVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, labels = data[0].to(device), data[1].to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzlBwiXloe5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7f63660d-01a1-4374-fd69-1830b562b6f8"
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.198\n",
            "[1,  4000] loss: 1.175\n",
            "[1,  6000] loss: 1.197\n",
            "[1,  8000] loss: 1.180\n",
            "[1, 10000] loss: 1.157\n",
            "[1, 12000] loss: 1.186\n",
            "[2,  2000] loss: 1.179\n",
            "[2,  4000] loss: 1.191\n",
            "[2,  6000] loss: 1.192\n",
            "[2,  8000] loss: 1.172\n",
            "[2, 10000] loss: 1.178\n",
            "[2, 12000] loss: 1.175\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJSjpXHcomWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}