{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Captum_Text_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-8Wn3OIORQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -U spacy\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install torch torchvision\n",
        "!pip install captum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVn-UUrGOv8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4BKwtUbYRKP",
        "colab_type": "text"
      },
      "source": [
        "## R1 Changin the English model\n",
        "\n",
        "- I am installing the en_core_web_sm model\n",
        "- so the next line gives me an error \n",
        "\n",
        "The original line was \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "spacy.load('en')\n",
        "```\n",
        "\n",
        "this was changed to \n",
        "\n",
        "```\n",
        "spacy.load('en_core_web_sm')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRWby-SPwFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lwxTlV6PbQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFlnbv5bP7V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        #text = text.permute(1, 0)\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM7uRRviR7_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/pytorch/captum/raw/master/tutorials/models/imdb-model-cnn.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI4jvEcJSD9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('imdb-model-cnn.pt')\n",
        "model.eval()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRYIywIuSLpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_with_sigmoid(input):\n",
        "    return torch.sigmoid(model(input))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WOI3I5HYEye",
        "colab_type": "text"
      },
      "source": [
        "## R2:  So this is interesting :) \n",
        "\n",
        "- The original command was giving me an error that it couldn't load the `en` model\n",
        "- Remember it was giving an error when we first tried to load it at the start of the notebook\n",
        "- So I checked the underlying code, and in the defination for `Field` there is a `get_tokenizer` function which loads the `en` model.\n",
        "- Changed it to `en_web_core_sm`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnqL7VzbScIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = torchtext.data.Field(lower=True, \n",
        "                            tokenize='spacy') # Had to change this from the original default value of `spacy`"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taboJ1dCVUav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Label = torchtext.data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "get-7u1ZTd-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = torchtext.datasets.IMDB.splits(text_field=TEXT,\n",
        "                                      label_field=Label,\n",
        "                                      train='train',\n",
        "                                      test='test',\n",
        "                                      path='data/aclImdb')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678FmQoJZxAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efqHQmCMZvPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, _ = test.split(split_ratio = 0.04)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}