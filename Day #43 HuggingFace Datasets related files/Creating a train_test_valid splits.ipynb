{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This for uploading the dataset to the huggingface datasets sprint\n",
    "# Adding all the files together \n",
    "# Adding a hash to refer back to the original files\n",
    "# Converting the sentiment scores to pos, neg & neu\n",
    "# pos > +0.1\n",
    "# neg < -0.1\n",
    "# -0.1 <=neu <= +0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUE if you are running a TEST scenario. If yes then read only one file\n",
    "### Default if FALSE and read all the files\n",
    "\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...dutch_tweets_chunk1.json\n",
      "Shape of file read...(27142, 23)\n",
      "Reading file...dutch_tweets_chunk2.json\n",
      "Shape of file read...(27130, 23)\n",
      "Reading file...dutch_tweets_chunk5.json\n",
      "Shape of file read...(27104, 23)\n",
      "Reading file...dutch_tweets_chunk7.json\n",
      "Shape of file read...(27234, 23)\n",
      "Reading file...dutch_tweets_chunk9.json\n",
      "Shape of file read...(27221, 23)\n",
      "Reading file...dutch_tweets_chunk6.json\n",
      "Shape of file read...(27026, 23)\n",
      "Reading file...dutch_tweets_chunk3.json\n",
      "Shape of file read...(27112, 23)\n",
      "Reading file...dutch_tweets_chunk4.json\n",
      "Shape of file read...(27217, 23)\n",
      "Reading file...dutch_tweets_chunk0.json\n",
      "Shape of file read...(27019, 23)\n",
      "Reading file...dutch_tweets_chunk8.json\n",
      "Shape of file read...(27137, 23)\n"
     ]
    }
   ],
   "source": [
    "filenames = list()\n",
    "dutch_tweets = pd.DataFrame()\n",
    "for file in os.listdir('/home/ubuntu'):\n",
    "    if \"dutch_tweets_chunk\" in file:\n",
    "            filenames.append(file)\n",
    "            print(f\"Reading file...{file}\")\n",
    "            temp = pd.read_json(file)\n",
    "            print(f\"Shape of file read...{temp.shape}\")\n",
    "            dutch_tweets = pd.concat([dutch_tweets, temp])\n",
    "            if TEST:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_text', 'text_translation', 'created_at', 'screen_name',\n",
       "       'description', 'desc_translation', 'weekofyear', 'weekday', 'day',\n",
       "       'month', 'year', 'location', 'point_info', 'point', 'latitude',\n",
       "       'longitude', 'altitude', 'province', 'hisco_standard', 'hisco_code',\n",
       "       'industry', 'sentiment_pattern', 'subjective_pattern'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column..using the following rule\n",
    "# Converting the sentiment scores to pos, neg & neu\n",
    "# pos > +0.1\n",
    "# neg < -0.1\n",
    "# -0.1 <=neu <= +0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(sentiment_score):\n",
    "    if sentiment_score > 0.1:\n",
    "        return 'pos'\n",
    "    elif sentiment_score < -0.1:\n",
    "        return 'neg'\n",
    "    else:\n",
    "        return 'neu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.1 ms, sys: 0 ns, total: 77.1 ms\n",
      "Wall time: 77.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dutch_tweets['label'] = dutch_tweets['sentiment_pattern'].apply(lambda x: label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    157734\n",
       "pos     71260\n",
       "neg     42348\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_tweets.drop(['created_at'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_text', 'text_translation', 'screen_name', 'description',\n",
       "       'desc_translation', 'weekofyear', 'weekday', 'day', 'month', 'year',\n",
       "       'location', 'point_info', 'point', 'latitude', 'longitude', 'altitude',\n",
       "       'province', 'hisco_standard', 'hisco_code', 'industry',\n",
       "       'sentiment_pattern', 'subjective_pattern', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text              object\n",
       "text_translation       object\n",
       "screen_name            object\n",
       "description            object\n",
       "desc_translation       object\n",
       "weekofyear            float64\n",
       "weekday               float64\n",
       "day                   float64\n",
       "month                 float64\n",
       "year                  float64\n",
       "location               object\n",
       "point_info             object\n",
       "point                  object\n",
       "latitude              float64\n",
       "longitude             float64\n",
       "altitude              float64\n",
       "province               object\n",
       "hisco_standard         object\n",
       "hisco_code             object\n",
       "industry                 bool\n",
       "sentiment_pattern     float64\n",
       "subjective_pattern    float64\n",
       "label                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_text',\n",
       " 'text_translation',\n",
       " 'screen_name',\n",
       " 'description',\n",
       " 'desc_translation',\n",
       " 'location',\n",
       " 'point_info',\n",
       " 'point',\n",
       " 'province',\n",
       " 'hisco_standard',\n",
       " 'hisco_code',\n",
       " 'label']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_columns = list(dutch_tweets.loc[:, dutch_tweets.dtypes == object].columns)\n",
    "obj_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_tweets[obj_columns] = dutch_tweets[obj_columns].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text                  0\n",
       "text_translation           0\n",
       "screen_name                0\n",
       "description                0\n",
       "desc_translation           0\n",
       "weekofyear                14\n",
       "weekday                   20\n",
       "day                       14\n",
       "month                     20\n",
       "year                      20\n",
       "location                   0\n",
       "point_info                 0\n",
       "point                      0\n",
       "latitude              136897\n",
       "longitude             136897\n",
       "altitude               16917\n",
       "province                   0\n",
       "hisco_standard             0\n",
       "hisco_code                 0\n",
       "industry                   0\n",
       "sentiment_pattern          0\n",
       "subjective_pattern         0\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_tweets[[\"latitude\", \"longitude\", \"altitude\", \"month\", \"year\", \"weekofyear\", \"weekday\", \"day\"]] = dutch_tweets[[\"latitude\", \"longitude\", \"altitude\", \"month\", \"year\",\"weekofyear\", \"weekday\", \"day\"]].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_tweets[[\"full_text\", \"text_translation\", \"screen_name\", \"description\", \"desc_translation\", \"location\", \"point_info\", \"point\", \"province\", \"hisco_standard\", \"hisco_code\"]] =  dutch_tweets[[\"full_text\", \"text_translation\", \"screen_name\", \"description\", \"desc_translation\", \"location\", \"point_info\", \"point\", \"province\", \"hisco_standard\", \"hisco_code\"]].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude      0\n",
       "longitude     0\n",
       "altitude      0\n",
       "weekofyear    0\n",
       "weekday       0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets[[\"latitude\", \"longitude\", \"altitude\", \"weekofyear\", \"weekday\", \"day\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text             0\n",
       "text_translation      0\n",
       "screen_name           0\n",
       "description           0\n",
       "desc_translation      0\n",
       "weekofyear            0\n",
       "weekday               0\n",
       "day                   0\n",
       "month                 0\n",
       "year                  0\n",
       "location              0\n",
       "point_info            0\n",
       "point                 0\n",
       "latitude              0\n",
       "longitude             0\n",
       "altitude              0\n",
       "province              0\n",
       "hisco_standard        0\n",
       "hisco_code            0\n",
       "industry              0\n",
       "sentiment_pattern     0\n",
       "subjective_pattern    0\n",
       "label                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(dutch_tweets.drop([\"label\"], axis=1), dutch_tweets['label'], test_size=0.4, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162805, 22) (162805,)\n",
      "(108537, 22) (108537,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, val_x, test_y, val_y,  = train_test_split(test_x, test_y, test_size=0.5, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54269, 22) (54269,)\n",
      "(54268, 22) (54268,)\n"
     ]
    }
   ],
   "source": [
    "print(val_x.shape, val_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162805, 23)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_x, train_y], axis=1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54268, 23)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([test_x, test_y], axis=1)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54269, 23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.concat([val_x, val_y], axis=1)\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_translation</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_translation</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>province</th>\n",
       "      <th>hisco_standard</th>\n",
       "      <th>hisco_code</th>\n",
       "      <th>industry</th>\n",
       "      <th>sentiment_pattern</th>\n",
       "      <th>subjective_pattern</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>RT @Ole_S_Hansen: The HG #copper fund short mo...</td>\n",
       "      <td>RT @Ole_S_Hansen: The HG #copper fund short mo...</td>\n",
       "      <td>CellarPolitics</td>\n",
       "      <td>Warehouse Coordinator | (Precious) Metals Zeal...</td>\n",
       "      <td>Warehouse Coordinator | (Precious) Metals Zeal...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.500170</td>\n",
       "      <td>5.748082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flevoland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>RT @autistmijwat: @AutismeNVA @PASNederland @A...</td>\n",
       "      <td>RT @autistmijwat: @AutismeNVA @PASNederland @A...</td>\n",
       "      <td>monique_hl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.500170</td>\n",
       "      <td>5.748082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flevoland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26774</th>\n",
       "      <td>RT @utregsrealiste: @ang_haar Anders: zorgen o...</td>\n",
       "      <td>RT @utregsrealiste: @ang_haar Others worry abo...</td>\n",
       "      <td>Tarotfritts100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20712</th>\n",
       "      <td>Nu gisteren, maar leuk als je tijd hebt om ter...</td>\n",
       "      <td>Now yesterday, but fun if you have time to lis...</td>\n",
       "      <td>Fortpampus</td>\n",
       "      <td>#PAMPUS UNESCO werelderfgoed / eiland / https:...</td>\n",
       "      <td>#PAMPUS UNESCO World / Island / https://t.co/e...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>#carpoolen #op1 #corona ik denk dat carpoolen ...</td>\n",
       "      <td>#carpoolen # op1 #corona I think finally carpo...</td>\n",
       "      <td>warsdenker</td>\n",
       "      <td>dwarse denker. Waarom ?</td>\n",
       "      <td>lateral thinker. Why ?</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.897991</td>\n",
       "      <td>168.128378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "11367  RT @Ole_S_Hansen: The HG #copper fund short mo...   \n",
       "9462   RT @autistmijwat: @AutismeNVA @PASNederland @A...   \n",
       "26774  RT @utregsrealiste: @ang_haar Anders: zorgen o...   \n",
       "20712  Nu gisteren, maar leuk als je tijd hebt om ter...   \n",
       "13023  #carpoolen #op1 #corona ik denk dat carpoolen ...   \n",
       "\n",
       "                                        text_translation     screen_name  \\\n",
       "11367  RT @Ole_S_Hansen: The HG #copper fund short mo...  CellarPolitics   \n",
       "9462   RT @autistmijwat: @AutismeNVA @PASNederland @A...      monique_hl   \n",
       "26774  RT @utregsrealiste: @ang_haar Others worry abo...  Tarotfritts100   \n",
       "20712  Now yesterday, but fun if you have time to lis...      Fortpampus   \n",
       "13023  #carpoolen # op1 #corona I think finally carpo...      warsdenker   \n",
       "\n",
       "                                             description  \\\n",
       "11367  Warehouse Coordinator | (Precious) Metals Zeal...   \n",
       "9462                                                None   \n",
       "26774                                               None   \n",
       "20712  #PAMPUS UNESCO werelderfgoed / eiland / https:...   \n",
       "13023                            dwarse denker. Waarom ?   \n",
       "\n",
       "                                        desc_translation  weekofyear  weekday  \\\n",
       "11367  Warehouse Coordinator | (Precious) Metals Zeal...         6.0      6.0   \n",
       "9462                                                None        12.0      0.0   \n",
       "26774                                               None        31.0      6.0   \n",
       "20712  #PAMPUS UNESCO World / Island / https://t.co/e...        28.0      6.0   \n",
       "13023                             lateral thinker. Why ?        26.0      2.0   \n",
       "\n",
       "        day  month    year  ...   latitude   longitude altitude   province  \\\n",
       "11367   9.0    2.0  2020.0  ...  52.500170    5.748082      0.0  Flevoland   \n",
       "9462   16.0    3.0  2020.0  ...  52.500170    5.748082      0.0  Flevoland   \n",
       "26774   2.0    8.0  2020.0  ...   0.000000    0.000000      0.0      False   \n",
       "20712  12.0    7.0  2020.0  ...   0.000000    0.000000      0.0      False   \n",
       "13023  24.0    6.0  2020.0  ... -46.897991  168.128378      0.0      False   \n",
       "\n",
       "       hisco_standard  hisco_code industry sentiment_pattern  \\\n",
       "11367            None        None    False            -0.100   \n",
       "9462             None        None    False             0.000   \n",
       "26774            None        None    False             0.275   \n",
       "20712            None        None    False             0.600   \n",
       "13023            None        None    False             0.350   \n",
       "\n",
       "      subjective_pattern  label  \n",
       "11367           0.100000    neu  \n",
       "9462            0.000000    neu  \n",
       "26774           0.800000    pos  \n",
       "20712           0.966667    pos  \n",
       "13023           0.900000    pos  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_text             0\n",
      "text_translation      0\n",
      "screen_name           0\n",
      "description           0\n",
      "desc_translation      0\n",
      "weekofyear            0\n",
      "weekday               0\n",
      "day                   0\n",
      "month                 0\n",
      "year                  0\n",
      "location              0\n",
      "point_info            0\n",
      "point                 0\n",
      "latitude              0\n",
      "longitude             0\n",
      "altitude              0\n",
      "province              0\n",
      "hisco_standard        0\n",
      "hisco_code            0\n",
      "industry              0\n",
      "sentiment_pattern     0\n",
      "subjective_pattern    0\n",
      "label                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_df[:600].to_json(orient=\"records\")\n",
    "\n",
    "parsed = json.loads(result)\n",
    "\n",
    "with open('train.jsonl', 'w') as outfile:\n",
    "    json.dump(parsed, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_df[:200].to_json(orient=\"records\")\n",
    "\n",
    "parsed = json.loads(result)\n",
    "\n",
    "with open('test.jsonl', 'w') as outfile:\n",
    "    json.dump(parsed, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = val_df[:200].to_json(orient=\"records\")\n",
    "\n",
    "parsed = json.loads(result)\n",
    "\n",
    "with open('val.jsonl', 'w') as outfile:\n",
    "    json.dump(parsed, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 23)\n",
      "CPU times: user 24.7 ms, sys: 6 µs, total: 24.7 ms\n",
      "Wall time: 24 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_translation</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_translation</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>province</th>\n",
       "      <th>hisco_standard</th>\n",
       "      <th>hisco_code</th>\n",
       "      <th>industry</th>\n",
       "      <th>sentiment_pattern</th>\n",
       "      <th>subjective_pattern</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maar , er iets nuttigs mee doen ? Zie jij 'm v...</td>\n",
       "      <td>However, there is something useful to do with ...</td>\n",
       "      <td>RonaldMeeuwis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @daphneskopelos: Door de coronacrisis zijn ...</td>\n",
       "      <td>RT @daphneskopelos: The corona crisis are abou...</td>\n",
       "      <td>IBeugel</td>\n",
       "      <td>Journalist, programmamaker, schrijver, oud Bal...</td>\n",
       "      <td>Journalist, filmmaker, writer, former Balkans ...</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>38.995368</td>\n",
       "      <td>21.987713</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Geovation: What role do ethics and locatio...</td>\n",
       "      <td>RT @Geovation: What role do ethics play data a...</td>\n",
       "      <td>hanscees</td>\n",
       "      <td>Systeemdenker, eigenaar https://t.co/5Cgd9GwmW...</td>\n",
       "      <td>Systems Thinker, owner https://t.co/5Cgd9GwmWt...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>52.500170</td>\n",
       "      <td>5.748082</td>\n",
       "      <td>0</td>\n",
       "      <td>Flevoland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MollyJongFast: Laura Ingraham is going to ...</td>\n",
       "      <td>RT @MollyJongFast: Laura Ingraham is going to ...</td>\n",
       "      <td>LDUniGr</td>\n",
       "      <td>CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...</td>\n",
       "      <td>CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>53.219065</td>\n",
       "      <td>6.568008</td>\n",
       "      <td>0</td>\n",
       "      <td>Groningen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @kneeyockartee: Corona has robbed me of man...</td>\n",
       "      <td>RT @kneeyockartee: Corona has robbed me of man...</td>\n",
       "      <td>transxlucence</td>\n",
       "      <td>welkom in de chaos van mijn hoofd. geniet van ...</td>\n",
       "      <td>welcome to the chaos of my head. enjoy the con...</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>52.094975</td>\n",
       "      <td>5.109708</td>\n",
       "      <td>0</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Maar , er iets nuttigs mee doen ? Zie jij 'm v...   \n",
       "1  RT @daphneskopelos: Door de coronacrisis zijn ...   \n",
       "2  RT @Geovation: What role do ethics and locatio...   \n",
       "3  RT @MollyJongFast: Laura Ingraham is going to ...   \n",
       "4  RT @kneeyockartee: Corona has robbed me of man...   \n",
       "\n",
       "                                    text_translation    screen_name  \\\n",
       "0  However, there is something useful to do with ...  RonaldMeeuwis   \n",
       "1  RT @daphneskopelos: The corona crisis are abou...        IBeugel   \n",
       "2  RT @Geovation: What role do ethics play data a...       hanscees   \n",
       "3  RT @MollyJongFast: Laura Ingraham is going to ...        LDUniGr   \n",
       "4  RT @kneeyockartee: Corona has robbed me of man...  transxlucence   \n",
       "\n",
       "                                         description  \\\n",
       "0                                               None   \n",
       "1  Journalist, programmamaker, schrijver, oud Bal...   \n",
       "2  Systeemdenker, eigenaar https://t.co/5Cgd9GwmW...   \n",
       "3  CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...   \n",
       "4  welkom in de chaos van mijn hoofd. geniet van ...   \n",
       "\n",
       "                                    desc_translation  weekofyear  weekday  \\\n",
       "0                                               None          21        3   \n",
       "1  Journalist, filmmaker, writer, former Balkans ...          23        2   \n",
       "2  Systems Thinker, owner https://t.co/5Cgd9GwmWt...          18        4   \n",
       "3  CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...          21        0   \n",
       "4  welcome to the chaos of my head. enjoy the con...          37        6   \n",
       "\n",
       "   day  month  year  ...   latitude  longitude altitude   province  \\\n",
       "0   21      5  2020  ...   0.000000   0.000000        0      False   \n",
       "1    3      6  2020  ...  38.995368  21.987713        0      False   \n",
       "2    1      5  2020  ...  52.500170   5.748082        0  Flevoland   \n",
       "3   18      5  2020  ...  53.219065   6.568008        0  Groningen   \n",
       "4   13      9  2020  ...  52.094975   5.109708        0    Utrecht   \n",
       "\n",
       "   hisco_standard  hisco_code industry sentiment_pattern subjective_pattern  \\\n",
       "0            None        None    False               0.0                0.0   \n",
       "1            None        None    False               0.0                0.0   \n",
       "2            None        None    False               0.0                0.0   \n",
       "3            None        None    False               0.0                0.0   \n",
       "4            None        None    False               0.0                0.0   \n",
       "\n",
       "   label  \n",
       "0    neu  \n",
       "1    neu  \n",
       "2    neu  \n",
       "3    neu  \n",
       "4    neu  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_json(\"train.jsonl\", encoding=\"utf-8\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    346\n",
       "pos    157\n",
       "neg     97\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-3ef470a3d0aa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-3ef470a3d0aa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break here\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_json(\"test.jsonl\", encoding=\"utf-8\")\n",
    "print(test.shape)\n",
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dev = pd.read_json(\"dev.jsonl\", encoding=\"utf-8\")\n",
    "print(dev.shape)\n",
    "dev['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = open(\"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"train.jsonl\"\n",
    "with open(filepath, encoding=\"utf-8\") as f:\n",
    "    tweets = json.load(f)\n",
    "    for id_, data in enumerate(tweets):\n",
    "        print(data[\"full_text\"])\n",
    "        if id_>5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(line):\n",
    "    print(row)\n",
    "    if idx > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('test.jsonl') as reader:\n",
    "    for id_, row in enumerate(reader):\n",
    "        data = json.loads(row)\n",
    "        print(data)\n",
    "        if id_ >10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = None\n",
    "data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
