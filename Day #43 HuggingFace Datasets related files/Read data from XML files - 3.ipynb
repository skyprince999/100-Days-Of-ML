{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_2016 = os.listdir(\"wit/XML_releases/xml/\")\n",
    "filepath_2015 = os.listdir(\"wit/XML_releases/xml-20150616/\")\n",
    "filepath_2014 = os.listdir(\"wit/XML_releases/xml-20140120/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "210\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "print(len(filepath_2016))\n",
    "print(len(filepath_2015))\n",
    "print(len(filepath_2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_to_dict(tree):\n",
    "    dct = {tree.tag: {} if tree.attrib else None}\n",
    "    children = list(tree)\n",
    "    if children:\n",
    "        dd = defaultdict(list)\n",
    "        for dc in map(et_to_dict, children):\n",
    "            for k, v in dc.items():\n",
    "                dd[k].append(v)\n",
    "        dct = {tree.tag: dd}\n",
    "    if tree.attrib:\n",
    "        dct[tree.tag].update((k, v) for k, v in tree.attrib.items())\n",
    "    if tree.text:\n",
    "        text = tree.text.strip()\n",
    "        if children or tree.attrib:\n",
    "            if text:\n",
    "                dct[tree.tag][\"text\"] = text\n",
    "        else:\n",
    "            dct[tree.tag] = text\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files which are corrupted (truncated?)\n",
    "* XML_releases/xml-20150616/ted_ru-20150530.zip \n",
    "\n",
    "    *file_id* = 37 missing *wordnum*, *charnum* & *content*\n",
    " \n",
    "* ted_uk-20150530.zip\n",
    "    *file_id* = 6 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in filepath_2015:\n",
    "#     if file.startswith('._ted') or 'wit3.dtd' in file:\n",
    "#         continue\n",
    "#     else:\n",
    "#         try:\n",
    "#             with zipfile.ZipFile(\"wit/XML_releases/xml-20150616//\" + file) as zf:\n",
    "#                 tree = ET.parse(zf.open(file[:-3]+\"xml\"))\n",
    "#                 root = tree.getroot()\n",
    "#                 lang1_talks = et_to_dict(root)\n",
    "#         except:\n",
    "#             print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will use the next few code blocks to test the validity of each file \n",
    "\n",
    "Result after running the next few blocks:\n",
    "\n",
    "- Added checks to check if description & title fields are present. As a default behaviour also added a \" \" via get \n",
    "\n",
    "- Sometimes content & transcriptions are not present. Checked before assigning it to a variable. \n",
    "\n",
    "Both the above changes ensure that there are no further errors. Integrated it into the data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2016 = \"wit/XML_releases/xml/\"\n",
    "path_2015 = \"wit/XML_releases/xml-20150616/\"\n",
    "path_2014 = \"wit/XML_releases/xml-20140120/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF TRANSLATION: 5\n",
      "CPU times: user 3min 3s, sys: 6.53 s, total: 3min 9s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "translation = list()\n",
    "for file in filepath_2016:\n",
    "    if file.startswith('._ted') or 'wit3.dtd' in file:\n",
    "        continue\n",
    "    else:\n",
    "        # Get language code\n",
    "        try:\n",
    "            lang_code = file.split('-')[0].replace(\"ted_\", \"\") \n",
    "        except:\n",
    "            print(f\"ERROR: Reading language code for file:: {file}\")\n",
    "            \n",
    "        # Break if the file has malformed XML\n",
    "        try:\n",
    "            with zipfile.ZipFile(path_2016 + file) as zf:\n",
    "                tree = ET.parse(zf.open(file[:-3]+\"xml\"))\n",
    "                root = tree.getroot()\n",
    "                lang_talks = et_to_dict(root).get('xml').get('file')\n",
    "        except:\n",
    "            print(f\"ERROR: Malformed or truncated XML file:: {file}\")\n",
    "            continue\n",
    "        \n",
    "        lang_talksids = [talk.get(\"head\")[0].get(\"talkid\") for talk in lang_talks]\n",
    "        \n",
    "        translation = list()\n",
    "        for talkid in lang_talksids:\n",
    "            source = list(filter(lambda talk: talk['head'][0]['talkid'] == talkid, lang_talks))\n",
    "            if len(source) == 0:\n",
    "                print(f\"No talks found for talkid::{talkid} and file:: {file}\")\n",
    "                pass\n",
    "            else:\n",
    "                source = source[0]\n",
    "            try:\n",
    "\n",
    "                if source['head'][0]['description']:\n",
    "                    if source['head'][0]['description'][0]:\n",
    "                        temp_dict = dict()\n",
    "                        temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_1\"\n",
    "                        temp_dict[lang_code] =  source['head'][0].get('description', \" \")[0].replace(\"TED Talk Subtitles and Transcript: \", \"\")\n",
    "                        translation.append(temp_dict)\n",
    "            except:\n",
    "                print(f\"ERROR: Reading description for talkid::{talkid}, file:: {file}\")\n",
    "            \n",
    "            try:\n",
    "                if source['head'][0]['title']:\n",
    "                    if source['head'][0]['title'][0]:\n",
    "                        temp_dict = dict()\n",
    "                        temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_2\"\n",
    "                        temp_dict[lang_code] =  source['head'][0]['title'][0]\n",
    "                        translation.append(temp_dict)\n",
    "            except:\n",
    "                print(f\"ERROR: Reading title for talkid::{talkid}, file:: {file}\")\n",
    "                \n",
    "            try:\n",
    "                if source.get('head')[0].get('transcription'): \n",
    "                    source_transc = source.get('head')[0].get('transcription')[0].get('seekvideo')\n",
    "                    transcriptions = [{'id': s.get('id'), lang_code: s.get('text')} for s in source_transc]\n",
    "                    translation.extend(transcriptions)\n",
    "            except:\n",
    "                print(f\"ERROR: Reading transcriptions for talkid::{talkid}, file:: {file}\")\n",
    "                \n",
    "print(f\"LENGTH OF TRANSLATION: {len(translation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766\n",
      "ja\n"
     ]
    }
   ],
   "source": [
    "filepath = path_2015\n",
    "filename = \"ted_ja-20150530.zip\"\n",
    "\n",
    "with zipfile.ZipFile(filepath + filename) as zf:\n",
    "    tree = ET.parse(zf.open(filename[:-3]+\"xml\"))\n",
    "    root = tree.getroot()\n",
    "    lang_talks = et_to_dict(root).get('xml').get('file')\n",
    "    lang_code = filename.split('-20')[0].replace(\"ted_\",\"\")\n",
    "\n",
    "print(len(lang_talks))\n",
    "print(lang_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "talkid = \"1435\"\n",
    "source = list(filter(lambda talk: talk['head'][0]['talkid'][0] == talkid, lang_talks))\n",
    "source = source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'head': [defaultdict(list,\n",
       "                          {'url': ['http://www.ted.com/talks/reuben_margolin_sculpting_waves_in_wood_and_time'],\n",
       "                           'pagesize': ['77440'],\n",
       "                           'dtime': ['Mon Dec 22 11:49:33 CET 2014'],\n",
       "                           'encoding': ['UTF-8'],\n",
       "                           'content-type': ['text/html; charset=utf-8'],\n",
       "                           'keywords': ['talks, TED Conference, art, culture, design, nature'],\n",
       "                           'speaker': ['Reuben Margolin'],\n",
       "                           'talkid': ['1435'],\n",
       "                           'videourl': ['http://download.ted.com/talks/ReubenMargolin_2012.mp4'],\n",
       "                           'videopath': ['talks/ReubenMargolin_2012.mp4'],\n",
       "                           'date': ['2012/03/01'],\n",
       "                           'wordnum': ['0'],\n",
       "                           'charnum': ['0']})],\n",
       "             'content': [None],\n",
       "             'id': '697'})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1779_1', 'fa': ' '}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict = dict()\n",
    "\n",
    "temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_1\"\n",
    "temp_dict[lang_code] =  source['head'][0].get('description', \" \")[0].replace(\"TED Talk Subtitles and Transcript: \", \"\")\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source['head'][0].get('title', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source['head'][0].get('title'):\n",
    "    if source['head'][0].get('title')[0]:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_2\"\n",
    "        temp_dict[lang_code] =  source['head'][0].get('title', \" \")[0]\n",
    "        print(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1779_1', 'fa': ' '}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source.get('head')[0].get('transcription'): \n",
    "    source_transc = source.get('head')[0].get('transcription')[0].get('seekvideo')\n",
    "    transcriptions = [{'id': s.get('id'), lang_code: s.get('text')} for s in source_transc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As is observed the returned dict file has the followin structure\n",
    "\n",
    "`lang1_talks['xml']['file']` --> list of all the records\n",
    "\n",
    "`lang1_talks['xml']['language']` --> language in which the records are transcribed/translated\n",
    "\n",
    "`lang1_talks['xml']['file'][N].keys()` :: *head*, *content*, *id*\n",
    "\n",
    "*id*: is an integer from 1 to N\n",
    "\n",
    "*content*: the entire content of the talk\n",
    "\n",
    "*head*: this is the meat that I am interested in! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_en = \"ted_en-20160408.zip\"\n",
    "# file_hi = \"ted_hi-20160408.zip\"\n",
    "\n",
    "# lang1 = \"_en\" # Originally done with en_hi\n",
    "# lang2 = \"_hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in filepath_2015:\n",
    "#     if file.startswith('._ted'):\n",
    "#         continue\n",
    "#     if lang1 in file:\n",
    "#         with zipfile.ZipFile(\"wit/XML_releases/xml-20150616//\" + file) as zf:\n",
    "#             tree = ET.parse(zf.open(file[:-3]+\"xml\"))\n",
    "#             root = tree.getroot()\n",
    "#             lang1_talks = et_to_dict(root)\n",
    "            \n",
    "#     elif lang2 in file:\n",
    "#         with zipfile.ZipFile(\"wit/XML_releases/xml-20150616//\" + file) as zf:\n",
    "#             tree = ET.parse(zf.open(file[:-3]+\"xml\"))\n",
    "#             root = tree.getroot()\n",
    "#             lang2_talks = et_to_dict(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *head* \n",
    "\n",
    "For some strange reason the head is a list of one. which has a __defaultdict__\n",
    "\n",
    "`head[0].keys()` --> *url*, *pagesize*, *dtime*, *encoding*, *content-type*, *keywords*, *speaker*, *talkid*, *videourl*, *videopath*, *date*, *title*, *description*, *transcription*, *translators*, *reviewers*, *wordnum*, *charnum*\n",
    "\n",
    "`head[0]['transcription'][0]['seekvideo']` is a list with sentence encoded with *id* & *text*\n",
    "\n",
    "`head[0]['description']` has the description of the talk & can also be used as a training example\n",
    "                         could do good to write a replace script for __\"TED Talk Subtitles and Transcript: \"__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang2_talks['xml']['file'][len(lang2_talks['xml']['file'])-1]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang2_talks['xml']['file'][0]['head'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang2_talks['xml']['file'][0]['head'][0]['transcription'][0]['seekvideo'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lang2_talks['xml']['file'][0]['head'][0]['transcription'][0]['seekvideo']\n",
    "# lang2_talks['xml']['file'][10]['head'][0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lets first strip the initial fluff\n",
    "# lang1_talks = lang1_talks['xml']['file']\n",
    "# lang2_talks = lang2_talks['xml']['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(lang2_talks)) # Validating that we have got a list with the same number of items\n",
    "# print(len(lang1_talks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang2_talks[10]['head'][0]['talkid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(filter(lambda talk: talk['id'] == '23', lang2_talks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang2_ids = [talk['head'][0]['talkid'] for talk in lang2_talks ]\n",
    "# lang1_ids = [talk['head'][0]['talkid'] for talk in lang1_talks ]\n",
    "\n",
    "# print(len(lang2_ids))\n",
    "# print(len(lang1_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comm_talkids = [talkid for talkid in lang2_ids if talkid in lang1_ids]\n",
    "# print(len(comm_talkids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code used to parse the XML file and create a translation pair for the given language pirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation = list()\n",
    "    \n",
    "# for talkid in comm_talkids:\n",
    "#     source = list(filter(lambda talk: talk['head'][0]['talkid'] == talkid, lang1_talks))\n",
    "#     target = list(filter(lambda talk: talk['head'][0]['talkid'] == talkid, lang2_talks))\n",
    "#     if len(source) == 0 or len(target) == 0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         source = source[0]\n",
    "#         target = target[0]\n",
    "        \n",
    "#     if source['head'][0]['description'][0]:\n",
    "#         if target['head'][0]['description'][0]:\n",
    "\n",
    "#             temp_dict = dict()\n",
    "#             temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_1\"\n",
    "#             temp_dict['en'] =  source['head'][0].get('description', \" \")[0].replace(\"TED Talk Subtitles and Transcript: \", \"\")\n",
    "#             temp_dict['hi'] =  target['head'][0].get('description', \" \")[0].replace(\"TED Talk Subtitles and Transcript: \", \"\")\n",
    "#             translation.append(temp_dict)\n",
    "\n",
    "#     temp_dict = dict()\n",
    "#     temp_dict['id'] = source['head'][0].get('talkid')[0] + \"_2\"\n",
    "#     temp_dict['en'] =  source['head'][0]['title'][0]\n",
    "#     temp_dict['hi'] =  target['head'][0]['title'][0]\n",
    "#     translation.append(temp_dict)\n",
    "    \n",
    "#     source_transc = source.get('head')[0].get('transcription')[0].get('seekvideo')\n",
    "#     target_transc = target.get('head')[0].get('transcription')[0].get('seekvideo')\n",
    "    \n",
    "#     transc = zip(source_transc, target_transc)\n",
    "#     transcriptions = [{'id': s.get('id'), 'en': s.get('text'), 'hi': t.get('text')} for s, t in transc]\n",
    "#     translation.extend(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if target['head'][0]['description']: \n",
    "#     print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
