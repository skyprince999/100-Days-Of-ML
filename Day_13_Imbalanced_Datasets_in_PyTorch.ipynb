{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day #13_Imbalanced Datasets in PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAEAhn41qWKiGzDPhgM253",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyprince999/100-Days-Of-ML/blob/master/Day_13_Imbalanced_Datasets_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHmKv5xEpqs8",
        "colab_type": "text"
      },
      "source": [
        "In many machne learning competitions we come across imbalanced datasets. Say in a rare disease identification challenge, the target variable may just be 0.1% of the entire dataset. Traditionally this is a challenge for most ML practitioners. \n",
        "\n",
        "Normally the way to overcome this is by using either one of the two ways of balancing the dataset:\n",
        "\n",
        "\n",
        "*   Undersampling the majority class\n",
        "*   Oversampling the minority class\n",
        "\n",
        "When you undersample the majority class, it generally leads to a loss of information. \n",
        "\n",
        "While oversampling the minority class can lead to overfitting to those particular examples. \n",
        "\n",
        "In this colab notebook, we use PyTorchs `ImbalancedDatasetSampler` to do the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   Rebalanced the class distributions when sampling from the imbalanced dataset\n",
        "2.   Estimate the sampling weights automatically\n",
        "3. Avoid creating a balanced dataset\n",
        "4. Mitigate overfitting by the use of data augmentations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSQrTcSragx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}