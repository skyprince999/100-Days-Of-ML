{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbj6GwOx40bPl2AnSlGubh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyprince999/100-Days-Of-ML/blob/master/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnz8beJPC_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijbC3ufoVLm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa07MuOEXQ_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f1f7b86a-1a53-4ef0-e287-7ea461c6f867"
      },
      "source": [
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_htTfVRXUUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20f15de4-f490-4de4-cb16-193f0bfde839"
      },
      "source": [
        "params = list(net.parameters()) # learnable parameters of the model\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK5nNaA4Xg78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "58007cf1-6042-49e5-ba5f-b0b6327d0202"
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0807,  0.1883,  0.0030,  0.1156,  0.0911,  0.1073,  0.0934,  0.0993,\n",
            "         -0.0723,  0.0545]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pabAGXTKXraD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad() # zero-fy all the gradients\n",
        "\n",
        "out.backward(torch.randn(1, 10)) # populate all bckward prop parameters with random weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g313jyNdYRAe",
        "colab_type": "text"
      },
      "source": [
        "torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
        "\n",
        "For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
        "\n",
        "If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6PgKsAYG1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "177f7189-701d-4023-c28a-92f1c337e2ad"
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0120, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPVgLstUev_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3cc9019a-022b-4d8f-d070-fbf5740874c6"
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f3cdaf96400>\n",
            "<AddmmBackward object at 0x7f3cdaf96400>\n",
            "<AccumulateGrad object at 0x7f3d3d4887b8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6uu9CtMfG6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b3b205b9-b789-49c4-d1c0-f06ba3291f7a"
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([ 0.0015, -0.0038,  0.0121,  0.0010,  0.0097,  0.0069])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jPfZHCfTbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01 # Updating the weights using SGD - Stochastic Gradient descent \n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLe9188BfmCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f49365e-121d-40b5-beec-6702f5c47fef"
      },
      "source": [
        "for f in net.parameters():\n",
        "  print(f)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0098,  0.2013, -0.2911],\n",
            "          [-0.0832, -0.0513, -0.1137],\n",
            "          [-0.2934, -0.0344,  0.2736]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1649, -0.0928,  0.3074],\n",
            "          [-0.2847, -0.0518,  0.3307],\n",
            "          [-0.1339, -0.0758,  0.1598]]],\n",
            "\n",
            "\n",
            "        [[[-0.0085,  0.0567, -0.0637],\n",
            "          [-0.2711,  0.2255,  0.2951],\n",
            "          [-0.2680, -0.2923, -0.1485]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3205,  0.3329, -0.3125],\n",
            "          [-0.2410, -0.0199,  0.0375],\n",
            "          [ 0.2822, -0.2193, -0.1531]]],\n",
            "\n",
            "\n",
            "        [[[-0.2384, -0.0442, -0.0415],\n",
            "          [-0.2063,  0.0297, -0.1050],\n",
            "          [-0.2053, -0.0027, -0.0978]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0547, -0.0086, -0.1587],\n",
            "          [-0.0122, -0.0067,  0.2708],\n",
            "          [ 0.1789, -0.1853, -0.2696]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2036, -0.3057, -0.0980, -0.1694,  0.1465, -0.1779],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[-8.7797e-02,  2.8548e-02, -6.1985e-03],\n",
            "          [ 1.0192e-01,  1.0771e-01,  1.7038e-02],\n",
            "          [ 1.1606e-01,  5.6706e-03, -1.3088e-01]],\n",
            "\n",
            "         [[ 1.0902e-01,  8.8181e-03, -1.1948e-01],\n",
            "          [-1.2962e-01, -6.8290e-02, -7.3563e-03],\n",
            "          [ 7.5595e-02, -1.2845e-01,  1.3299e-01]],\n",
            "\n",
            "         [[-1.1168e-01,  6.6043e-02,  7.5827e-02],\n",
            "          [ 5.7448e-02, -7.5713e-02, -9.3304e-02],\n",
            "          [ 9.4195e-02,  2.0613e-03, -7.6107e-02]],\n",
            "\n",
            "         [[ 8.2772e-02,  2.6532e-02,  5.3496e-02],\n",
            "          [ 8.3093e-02, -1.3301e-01,  1.2216e-01],\n",
            "          [ 4.0162e-02,  8.6876e-02, -7.9741e-02]],\n",
            "\n",
            "         [[ 8.8708e-02,  6.0385e-02, -1.3173e-01],\n",
            "          [-6.1830e-02, -3.9271e-02, -8.5469e-02],\n",
            "          [ 1.0364e-01,  1.3498e-01, -8.7443e-02]],\n",
            "\n",
            "         [[ 9.0096e-02,  7.8151e-02,  3.3172e-03],\n",
            "          [-4.2370e-02,  8.6318e-02, -1.3425e-01],\n",
            "          [-8.1553e-03,  1.2562e-01,  9.0930e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.4381e-03, -3.0986e-02, -8.1146e-02],\n",
            "          [ 1.2412e-01, -3.9988e-02, -1.0858e-01],\n",
            "          [-7.4697e-02, -1.2492e-01,  4.7876e-02]],\n",
            "\n",
            "         [[-8.0720e-02,  4.5082e-02, -1.3018e-01],\n",
            "          [-9.9178e-02, -7.3488e-02, -1.2018e-01],\n",
            "          [-1.1151e-01,  3.8726e-02, -1.1354e-01]],\n",
            "\n",
            "         [[-3.7266e-02,  3.7320e-02,  2.0656e-02],\n",
            "          [ 6.8400e-02, -9.9221e-02,  6.0455e-02],\n",
            "          [ 6.9292e-02,  1.0744e-01,  1.3025e-01]],\n",
            "\n",
            "         [[-1.2533e-01, -6.9034e-02, -1.3520e-01],\n",
            "          [ 1.7163e-02,  7.8526e-02, -9.1294e-02],\n",
            "          [-5.1835e-02,  5.2273e-02, -4.7609e-02]],\n",
            "\n",
            "         [[ 3.6211e-02,  9.4608e-02,  7.0112e-02],\n",
            "          [ 5.7472e-02,  1.2256e-03, -1.2734e-01],\n",
            "          [ 5.6024e-02,  1.0990e-01, -8.9559e-02]],\n",
            "\n",
            "         [[-2.3990e-02, -6.4137e-02,  1.2138e-01],\n",
            "          [ 2.1785e-02, -7.1094e-02, -7.9392e-02],\n",
            "          [ 5.3849e-02,  8.8441e-02,  1.3679e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.8601e-02, -1.1827e-01,  1.3866e-02],\n",
            "          [-5.0782e-02,  7.1800e-03,  1.8520e-02],\n",
            "          [ 1.1587e-03,  2.3158e-02, -6.2815e-03]],\n",
            "\n",
            "         [[ 6.6517e-02,  6.2753e-02,  5.5245e-02],\n",
            "          [-6.8151e-02, -9.5240e-02,  5.6665e-02],\n",
            "          [-1.0141e-02,  5.3285e-02, -1.6843e-02]],\n",
            "\n",
            "         [[ 4.7844e-02,  1.3580e-01, -1.1081e-01],\n",
            "          [-4.1287e-02, -1.4330e-02,  5.0344e-02],\n",
            "          [ 6.7691e-02, -8.7552e-03,  9.7352e-02]],\n",
            "\n",
            "         [[-2.1107e-02,  6.4207e-03, -2.7641e-02],\n",
            "          [ 2.4549e-02,  3.8648e-02, -8.3022e-02],\n",
            "          [ 8.9538e-02,  2.1568e-02, -2.5964e-02]],\n",
            "\n",
            "         [[ 7.1730e-02, -7.2577e-02, -8.6221e-02],\n",
            "          [-5.5758e-02, -3.3716e-03, -1.1785e-01],\n",
            "          [-5.2943e-02,  7.5197e-02, -6.9573e-02]],\n",
            "\n",
            "         [[ 1.3103e-01, -1.0243e-02,  8.1213e-02],\n",
            "          [-4.6526e-03, -3.7502e-02,  2.6636e-02],\n",
            "          [-7.9407e-03, -4.0792e-02, -3.2424e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.5330e-02,  1.2407e-01, -4.1324e-02],\n",
            "          [-9.7969e-02, -1.2106e-01, -1.7533e-02],\n",
            "          [-5.2002e-03, -6.3371e-02, -7.1286e-02]],\n",
            "\n",
            "         [[ 6.9825e-02, -1.2888e-01, -5.1457e-02],\n",
            "          [ 6.0467e-02,  7.3680e-02, -1.2397e-01],\n",
            "          [ 1.0394e-01, -1.2647e-01,  2.1333e-02]],\n",
            "\n",
            "         [[-1.2236e-01,  1.1759e-01,  8.5025e-02],\n",
            "          [ 3.7572e-02, -9.0497e-02, -9.4875e-02],\n",
            "          [-1.1412e-01, -6.9825e-02,  5.9972e-02]],\n",
            "\n",
            "         [[-1.1958e-01, -4.4932e-02,  6.2973e-02],\n",
            "          [ 7.3759e-02,  7.6663e-02,  1.4712e-02],\n",
            "          [ 1.3080e-01,  1.3587e-01,  2.6118e-02]],\n",
            "\n",
            "         [[ 1.0199e-01, -8.6963e-02,  1.1108e-01],\n",
            "          [-1.2483e-01,  1.2492e-01,  1.2650e-01],\n",
            "          [-6.5136e-02,  4.3315e-02, -8.6405e-02]],\n",
            "\n",
            "         [[ 2.1898e-02,  2.2087e-02,  1.2960e-01],\n",
            "          [-5.0198e-02,  3.2549e-02, -1.1646e-01],\n",
            "          [-1.2848e-01, -5.3752e-02,  2.8145e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.5364e-02,  1.3726e-02, -8.2955e-02],\n",
            "          [ 4.2976e-02, -8.9036e-02, -9.5121e-02],\n",
            "          [-8.5107e-02,  1.1253e-01, -1.1717e-01]],\n",
            "\n",
            "         [[-2.6283e-02, -2.5719e-02, -6.3780e-02],\n",
            "          [-6.9415e-02,  1.1198e-01, -8.0744e-02],\n",
            "          [-9.2982e-02, -1.0524e-01, -7.7190e-02]],\n",
            "\n",
            "         [[ 8.0775e-02,  1.0440e-01,  1.0352e-02],\n",
            "          [-1.2870e-01, -5.5140e-02,  9.8294e-02],\n",
            "          [-5.8454e-02,  5.8675e-02,  8.5332e-02]],\n",
            "\n",
            "         [[-7.6892e-02, -7.8454e-02, -7.0509e-02],\n",
            "          [ 1.0521e-01,  6.4980e-02, -3.0902e-02],\n",
            "          [ 2.4947e-02, -5.2485e-02,  1.3209e-01]],\n",
            "\n",
            "         [[-4.8726e-02,  4.6828e-02,  7.3083e-02],\n",
            "          [-5.5883e-03, -4.6202e-02,  7.6067e-02],\n",
            "          [ 9.3625e-02, -5.7264e-02,  1.2475e-01]],\n",
            "\n",
            "         [[ 4.9628e-02,  1.2891e-01,  1.6864e-02],\n",
            "          [-1.6919e-02, -7.6367e-02, -5.5347e-02],\n",
            "          [ 1.0131e-01, -4.1998e-02, -8.3362e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1112e-01,  8.0284e-02, -9.0115e-03],\n",
            "          [ 1.2655e-01,  7.6694e-02, -9.0007e-02],\n",
            "          [ 2.7219e-02, -8.4470e-02,  5.9449e-02]],\n",
            "\n",
            "         [[ 1.1493e-01,  1.0884e-01,  3.6571e-03],\n",
            "          [-8.9061e-02, -8.7726e-02, -9.6111e-02],\n",
            "          [-7.6402e-02,  2.2798e-02, -6.6566e-02]],\n",
            "\n",
            "         [[-3.8559e-02, -1.0026e-01, -3.7733e-02],\n",
            "          [ 1.5841e-02,  1.9265e-02, -2.0404e-02],\n",
            "          [-6.4134e-02,  7.4295e-02,  1.7523e-02]],\n",
            "\n",
            "         [[ 3.4971e-02, -1.1925e-01, -5.5368e-02],\n",
            "          [ 7.8477e-02,  3.6883e-03, -1.3043e-01],\n",
            "          [ 1.8239e-02,  9.2020e-02,  1.0157e-01]],\n",
            "\n",
            "         [[ 7.1802e-02,  4.3365e-02,  7.2577e-02],\n",
            "          [-2.7534e-02, -9.4651e-02, -3.2129e-02],\n",
            "          [-1.3241e-01,  9.1850e-02, -3.9912e-02]],\n",
            "\n",
            "         [[-1.2858e-01,  5.4934e-02, -5.7374e-02],\n",
            "          [ 1.1554e-01,  1.1534e-01, -6.9224e-02],\n",
            "          [-6.4487e-02, -1.1305e-01,  3.2862e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2769e-02,  4.6261e-02, -1.2739e-01],\n",
            "          [-1.2246e-01, -9.4051e-02,  3.2402e-02],\n",
            "          [ 1.0438e-01,  7.0444e-02,  8.4186e-02]],\n",
            "\n",
            "         [[ 8.0274e-02, -6.0586e-02, -1.2760e-01],\n",
            "          [ 2.6201e-02, -3.5529e-02,  3.5835e-02],\n",
            "          [-6.8092e-02, -5.7636e-02, -7.0974e-02]],\n",
            "\n",
            "         [[ 1.2608e-02, -4.7532e-02, -1.1435e-01],\n",
            "          [-1.2918e-01,  1.3445e-01, -1.6309e-03],\n",
            "          [-8.1645e-02, -6.4587e-02, -3.9580e-02]],\n",
            "\n",
            "         [[-1.0923e-01, -1.0030e-02, -1.0648e-01],\n",
            "          [ 6.5893e-02,  2.0482e-02,  1.1228e-01],\n",
            "          [ 7.2459e-02, -7.2056e-02,  5.8689e-02]],\n",
            "\n",
            "         [[-1.2005e-03,  2.1510e-02,  2.2358e-02],\n",
            "          [-5.9430e-02,  6.2171e-02,  7.8146e-02],\n",
            "          [-7.2613e-02, -1.0170e-01, -6.0698e-02]],\n",
            "\n",
            "         [[ 8.0735e-02,  9.6566e-02,  4.6143e-02],\n",
            "          [-1.2718e-01, -1.2598e-01,  6.3604e-02],\n",
            "          [-1.2670e-01, -4.7170e-02,  4.9235e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.8118e-02,  7.3792e-02, -4.6623e-02],\n",
            "          [-1.2452e-01,  3.1109e-02,  7.6237e-02],\n",
            "          [-2.5908e-02,  5.2845e-02,  4.9228e-03]],\n",
            "\n",
            "         [[-9.0024e-02,  1.0786e-01,  7.8338e-02],\n",
            "          [-1.0708e-01, -1.2325e-01, -9.9884e-03],\n",
            "          [-8.4165e-02,  1.0354e-01, -1.2565e-01]],\n",
            "\n",
            "         [[ 1.8399e-02, -1.2295e-01,  6.0986e-02],\n",
            "          [-1.9704e-02, -7.9318e-02, -7.2407e-02],\n",
            "          [-1.0603e-01, -1.1334e-01,  6.0425e-02]],\n",
            "\n",
            "         [[ 6.3385e-02, -2.0668e-02,  7.8194e-03],\n",
            "          [ 2.1684e-02, -9.3226e-02, -4.5752e-03],\n",
            "          [-1.7899e-02,  4.9005e-03,  1.2403e-01]],\n",
            "\n",
            "         [[ 1.2015e-01, -2.3189e-03,  1.1301e-01],\n",
            "          [ 3.3230e-02,  7.1819e-02,  1.1327e-01],\n",
            "          [ 3.0405e-02,  1.2701e-01, -9.6209e-02]],\n",
            "\n",
            "         [[ 9.9852e-02, -1.2714e-01,  1.2851e-01],\n",
            "          [-7.6277e-02, -1.2883e-02,  2.2666e-02],\n",
            "          [ 7.0572e-02, -8.4487e-02, -3.0124e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.0098e-02,  5.4535e-05, -8.5622e-03],\n",
            "          [-6.7489e-02, -1.5574e-02,  1.3481e-01],\n",
            "          [ 1.0317e-01,  1.3580e-01, -1.2732e-01]],\n",
            "\n",
            "         [[-1.2618e-02, -1.0968e-02, -1.1342e-01],\n",
            "          [-3.4669e-02, -2.7157e-02,  5.7605e-02],\n",
            "          [ 1.2044e-03,  9.1263e-03, -3.4382e-02]],\n",
            "\n",
            "         [[-6.3372e-02,  1.5750e-02,  5.9786e-02],\n",
            "          [-1.1353e-01, -1.0546e-01,  5.8102e-02],\n",
            "          [-3.9405e-02,  1.7079e-02, -1.0223e-01]],\n",
            "\n",
            "         [[ 1.3179e-01,  5.1911e-02,  1.0574e-01],\n",
            "          [ 1.0240e-01,  1.2727e-01, -1.0964e-01],\n",
            "          [-8.5980e-02, -1.1780e-01,  2.0364e-02]],\n",
            "\n",
            "         [[ 5.0484e-02,  4.6967e-02,  2.7177e-02],\n",
            "          [ 6.1220e-02,  6.7795e-03,  1.2983e-01],\n",
            "          [ 1.1628e-01, -1.2325e-01,  5.5849e-02]],\n",
            "\n",
            "         [[-7.7493e-02, -1.2119e-01,  3.8483e-02],\n",
            "          [-1.1072e-01,  4.5672e-02,  1.0570e-01],\n",
            "          [ 1.1960e-01,  6.2299e-02,  6.9385e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.6432e-03, -6.4254e-02,  7.7508e-02],\n",
            "          [ 1.9632e-02, -1.0535e-01, -2.6205e-02],\n",
            "          [ 4.9604e-02, -1.0414e-01, -7.4652e-03]],\n",
            "\n",
            "         [[-1.2378e-01, -1.2958e-01,  8.7045e-02],\n",
            "          [ 4.4787e-02,  1.3500e-01,  8.5573e-03],\n",
            "          [ 4.4771e-02, -3.4755e-02, -3.5397e-02]],\n",
            "\n",
            "         [[ 5.8438e-02,  5.6071e-02, -3.1822e-02],\n",
            "          [-1.4724e-02,  7.5131e-02,  4.2178e-02],\n",
            "          [ 9.1922e-02,  5.5907e-02, -1.1143e-01]],\n",
            "\n",
            "         [[-6.1061e-02,  1.2881e-01,  2.2076e-02],\n",
            "          [ 8.5988e-02,  1.1541e-01,  2.7224e-02],\n",
            "          [ 1.2037e-02, -3.1191e-02,  5.5660e-03]],\n",
            "\n",
            "         [[ 8.8482e-05,  8.2825e-02,  3.1050e-02],\n",
            "          [ 1.1679e-01, -5.1415e-02, -1.2919e-01],\n",
            "          [ 1.7879e-02, -8.3589e-02,  8.3705e-02]],\n",
            "\n",
            "         [[-2.9403e-02, -5.1351e-02,  1.1483e-01],\n",
            "          [-1.1147e-02, -7.4544e-02,  1.0633e-01],\n",
            "          [-1.2024e-01, -7.1029e-02, -3.0131e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.2282e-02, -1.5133e-02,  1.2486e-01],\n",
            "          [ 7.7398e-02,  1.3525e-01,  2.9870e-02],\n",
            "          [-1.0248e-01, -1.2736e-01,  1.1906e-01]],\n",
            "\n",
            "         [[-1.0428e-01, -3.6311e-02,  8.0832e-02],\n",
            "          [ 9.6650e-02, -9.3605e-02,  6.2279e-02],\n",
            "          [ 2.7465e-02,  2.7341e-02, -1.2733e-01]],\n",
            "\n",
            "         [[ 7.8696e-03, -6.8509e-02,  6.1759e-02],\n",
            "          [-1.3009e-01,  2.6202e-02,  1.1089e-01],\n",
            "          [-1.0013e-01, -2.9047e-02, -1.1003e-01]],\n",
            "\n",
            "         [[-1.9246e-02,  8.5979e-02, -1.2570e-01],\n",
            "          [ 4.4714e-02, -4.4182e-02, -1.2011e-01],\n",
            "          [-1.2134e-01,  1.3158e-01, -6.7463e-02]],\n",
            "\n",
            "         [[ 9.6894e-02,  1.3493e-01,  9.1007e-02],\n",
            "          [-7.0352e-02, -4.0909e-02, -3.8763e-02],\n",
            "          [ 5.8495e-02, -5.8454e-03, -1.0485e-01]],\n",
            "\n",
            "         [[-4.0880e-02, -6.7906e-02, -5.8072e-02],\n",
            "          [ 1.1430e-01, -9.3763e-03,  1.0375e-01],\n",
            "          [-1.2936e-01, -3.5952e-02,  2.3086e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3860e-03,  1.3056e-02, -1.5986e-02],\n",
            "          [ 1.1328e-01,  1.1418e-01,  1.1724e-01],\n",
            "          [-9.3916e-02,  6.0155e-02,  9.7868e-02]],\n",
            "\n",
            "         [[-3.6866e-02,  2.4664e-02,  1.2516e-01],\n",
            "          [-1.1804e-01, -1.2006e-01, -2.8262e-02],\n",
            "          [ 9.0408e-02,  1.4170e-02, -2.8748e-02]],\n",
            "\n",
            "         [[ 5.9214e-02, -8.8808e-02, -9.5470e-02],\n",
            "          [ 1.3249e-01, -1.1157e-01,  2.4908e-02],\n",
            "          [-6.4093e-02,  4.8422e-02, -2.2418e-02]],\n",
            "\n",
            "         [[ 6.8218e-02,  3.6545e-02,  1.2854e-01],\n",
            "          [-3.9576e-02, -3.6388e-02, -6.0009e-02],\n",
            "          [-7.0631e-02, -3.9475e-02,  8.3068e-02]],\n",
            "\n",
            "         [[-2.1419e-02,  7.3491e-02,  8.4354e-03],\n",
            "          [-2.2457e-02,  2.9191e-02,  1.2966e-01],\n",
            "          [ 8.7012e-02,  8.5697e-02,  5.8760e-02]],\n",
            "\n",
            "         [[ 1.0598e-01,  2.7582e-02,  4.3219e-02],\n",
            "          [-7.8009e-03,  3.8919e-02, -2.0642e-03],\n",
            "          [ 1.2821e-01, -3.3670e-02,  1.2614e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7957e-02, -1.3009e-01, -1.7749e-03],\n",
            "          [ 1.0277e-01, -1.0466e-01,  1.1972e-01],\n",
            "          [ 5.6814e-02,  9.0333e-02,  1.3477e-01]],\n",
            "\n",
            "         [[-3.7672e-02,  6.3805e-02, -3.5678e-02],\n",
            "          [ 2.6596e-02, -8.8274e-02,  4.9647e-02],\n",
            "          [ 1.1149e-01, -4.8918e-02,  6.6459e-02]],\n",
            "\n",
            "         [[-7.6218e-02, -8.2711e-02,  9.4208e-03],\n",
            "          [ 1.1114e-01, -1.4715e-02, -1.0544e-03],\n",
            "          [-3.3204e-02, -1.2593e-01, -1.1687e-01]],\n",
            "\n",
            "         [[-8.9900e-02,  6.7372e-02,  1.3897e-02],\n",
            "          [ 8.1318e-02,  1.1652e-01, -2.8858e-02],\n",
            "          [-5.6085e-02,  7.4000e-02,  1.4088e-03]],\n",
            "\n",
            "         [[ 8.9136e-02,  6.4355e-02, -3.8367e-02],\n",
            "          [ 1.9716e-02, -3.8111e-02, -1.7095e-02],\n",
            "          [ 1.0726e-01, -4.9210e-02, -7.6851e-02]],\n",
            "\n",
            "         [[-3.7782e-02, -1.2366e-01,  1.0110e-01],\n",
            "          [-3.7715e-02,  6.1517e-02,  9.9224e-02],\n",
            "          [ 5.3184e-02,  9.2563e-02,  1.3142e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.2195e-02, -6.1782e-02, -8.1392e-02],\n",
            "          [-4.8866e-02,  1.0873e-02, -3.2806e-02],\n",
            "          [-6.3117e-02, -1.3455e-01,  8.7948e-02]],\n",
            "\n",
            "         [[ 1.1100e-01,  1.0526e-02, -7.7811e-02],\n",
            "          [-1.0961e-01, -3.3897e-02, -3.1400e-03],\n",
            "          [-2.7236e-02, -5.5828e-02,  8.9531e-02]],\n",
            "\n",
            "         [[-1.3105e-01, -9.6257e-02, -1.1543e-01],\n",
            "          [-1.2008e-01,  8.3999e-02, -7.8224e-02],\n",
            "          [ 9.7929e-02, -2.5670e-02,  1.1321e-01]],\n",
            "\n",
            "         [[-7.4660e-02,  7.4666e-02, -5.9536e-02],\n",
            "          [-2.1455e-02, -8.7026e-02,  1.1572e-01],\n",
            "          [-3.1380e-03, -1.0872e-01, -9.5647e-03]],\n",
            "\n",
            "         [[ 1.0677e-01, -1.2707e-01,  2.6218e-02],\n",
            "          [ 1.8211e-02,  1.3753e-02,  3.7288e-02],\n",
            "          [-1.2225e-01,  3.2151e-02, -1.3312e-01]],\n",
            "\n",
            "         [[ 1.2444e-01,  5.8975e-02,  1.3572e-01],\n",
            "          [ 1.8349e-02,  6.9753e-02, -1.9256e-02],\n",
            "          [ 2.0130e-02,  1.2675e-01, -1.2889e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.5561e-02, -6.5398e-02, -4.8738e-02],\n",
            "          [ 1.2308e-01,  5.9200e-02, -8.4044e-02],\n",
            "          [ 4.6944e-02, -4.2170e-02, -5.9434e-03]],\n",
            "\n",
            "         [[ 7.5410e-02, -7.1834e-02,  3.9462e-02],\n",
            "          [-5.2526e-02, -6.9121e-02, -1.0262e-01],\n",
            "          [-1.1165e-01, -8.4234e-02, -4.6048e-02]],\n",
            "\n",
            "         [[-4.7759e-02, -2.7562e-02, -1.1306e-02],\n",
            "          [ 1.1490e-01, -2.4537e-02,  5.6084e-02],\n",
            "          [ 7.2582e-02, -2.7122e-03,  8.9478e-02]],\n",
            "\n",
            "         [[ 1.0126e-01, -8.2704e-02, -9.9714e-02],\n",
            "          [-9.2723e-02,  3.1466e-02, -5.3648e-02],\n",
            "          [ 8.6451e-02,  7.9035e-02, -6.8970e-03]],\n",
            "\n",
            "         [[-8.2839e-02,  1.2250e-01, -1.1622e-01],\n",
            "          [-1.0637e-01, -9.0689e-02,  4.4442e-02],\n",
            "          [ 1.7327e-02, -2.8955e-02, -1.8160e-02]],\n",
            "\n",
            "         [[-1.0087e-01, -9.8013e-02,  1.2419e-01],\n",
            "          [-3.6811e-02,  2.1763e-02,  2.7390e-02],\n",
            "          [ 7.0836e-02,  1.1217e-01,  2.0612e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0555e-02, -7.7256e-02,  1.3524e-01],\n",
            "          [-9.5942e-02,  3.2103e-02,  9.8296e-02],\n",
            "          [ 7.1165e-02, -1.0928e-01, -6.7039e-02]],\n",
            "\n",
            "         [[ 1.3090e-01, -7.2266e-03, -5.7536e-02],\n",
            "          [ 2.9217e-03, -6.1611e-02, -1.7831e-02],\n",
            "          [ 3.7764e-02, -7.7007e-02,  4.9100e-02]],\n",
            "\n",
            "         [[-2.5854e-02, -6.1148e-02, -7.4127e-02],\n",
            "          [-6.8573e-02,  2.3429e-02,  5.2139e-02],\n",
            "          [ 1.2074e-01, -8.1006e-02, -2.7374e-03]],\n",
            "\n",
            "         [[-1.8242e-02, -3.3655e-02, -1.1384e-01],\n",
            "          [ 4.9555e-02, -5.9573e-02,  5.3097e-02],\n",
            "          [ 8.3297e-02, -1.1641e-01,  8.3673e-02]],\n",
            "\n",
            "         [[-5.0818e-02,  1.2223e-01, -2.4528e-02],\n",
            "          [-1.0983e-01,  1.1446e-01, -1.0521e-01],\n",
            "          [ 9.0109e-02, -6.8670e-02,  1.8572e-03]],\n",
            "\n",
            "         [[-1.1765e-01,  3.0110e-02, -6.2265e-02],\n",
            "          [ 3.5414e-02,  1.0497e-01,  8.7397e-02],\n",
            "          [-5.5120e-03,  8.8823e-02, -1.3153e-01]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1070,  0.1338, -0.0111, -0.0450,  0.0498,  0.0183,  0.1118, -0.0071,\n",
            "         0.1333,  0.0943,  0.0637, -0.0947, -0.1075, -0.0960,  0.0838, -0.0363],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0277,  0.0403,  0.0290,  ..., -0.0073,  0.0344, -0.0192],\n",
            "        [ 0.0221,  0.0263, -0.0279,  ...,  0.0252, -0.0355,  0.0082],\n",
            "        [-0.0109,  0.0094,  0.0078,  ...,  0.0047,  0.0272,  0.0205],\n",
            "        ...,\n",
            "        [-0.0163,  0.0149,  0.0330,  ...,  0.0372, -0.0235,  0.0263],\n",
            "        [-0.0052, -0.0084, -0.0098,  ...,  0.0163,  0.0401,  0.0122],\n",
            "        [ 0.0410, -0.0021, -0.0333,  ..., -0.0354, -0.0217,  0.0005]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0251, -0.0227,  0.0333, -0.0304, -0.0016,  0.0020,  0.0381, -0.0127,\n",
            "        -0.0258, -0.0219,  0.0350, -0.0008, -0.0081,  0.0165,  0.0077, -0.0229,\n",
            "         0.0320,  0.0194,  0.0223,  0.0020,  0.0281, -0.0198, -0.0260,  0.0030,\n",
            "         0.0354,  0.0008,  0.0030, -0.0322,  0.0394, -0.0124, -0.0344,  0.0163,\n",
            "         0.0336,  0.0285,  0.0333,  0.0208, -0.0401,  0.0067, -0.0013,  0.0251,\n",
            "        -0.0408, -0.0116, -0.0324,  0.0052,  0.0394,  0.0395,  0.0206, -0.0097,\n",
            "        -0.0329,  0.0314,  0.0263, -0.0242,  0.0060,  0.0166, -0.0287,  0.0335,\n",
            "        -0.0060, -0.0198,  0.0376,  0.0035, -0.0198,  0.0269,  0.0278,  0.0230,\n",
            "        -0.0252,  0.0415,  0.0056, -0.0284,  0.0104, -0.0114,  0.0368,  0.0233,\n",
            "         0.0110, -0.0332,  0.0006, -0.0294, -0.0310,  0.0019,  0.0287,  0.0214,\n",
            "         0.0182, -0.0113, -0.0074,  0.0221, -0.0309, -0.0169,  0.0275, -0.0148,\n",
            "        -0.0131,  0.0165, -0.0363, -0.0200,  0.0242, -0.0359, -0.0270, -0.0320,\n",
            "         0.0055, -0.0256,  0.0112,  0.0103,  0.0380, -0.0119,  0.0156,  0.0088,\n",
            "        -0.0180,  0.0367, -0.0310,  0.0383,  0.0280,  0.0274,  0.0110, -0.0193,\n",
            "        -0.0090, -0.0171, -0.0287,  0.0024, -0.0303,  0.0407,  0.0323, -0.0012],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0217, -0.0775, -0.0842,  ..., -0.0492, -0.0201,  0.0155],\n",
            "        [-0.0908,  0.0808, -0.0424,  ...,  0.0353, -0.0263,  0.0673],\n",
            "        [-0.0074, -0.0134, -0.0408,  ..., -0.0067, -0.0469,  0.0233],\n",
            "        ...,\n",
            "        [-0.0776,  0.0027, -0.0666,  ...,  0.0770, -0.0209, -0.0070],\n",
            "        [-0.0018,  0.0130,  0.0484,  ...,  0.0611, -0.0621,  0.0256],\n",
            "        [ 0.0888,  0.0675,  0.0602,  ...,  0.0264, -0.0405,  0.0025]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0285, -0.0333, -0.0186,  0.0343,  0.0903, -0.0787,  0.0469,  0.0721,\n",
            "         0.0400,  0.0259,  0.0135, -0.0396, -0.0747,  0.0139, -0.0541,  0.0651,\n",
            "         0.0351, -0.0616, -0.0407,  0.0765, -0.0454,  0.0565,  0.0633, -0.0442,\n",
            "         0.0046,  0.0207, -0.0082, -0.0905,  0.0623,  0.0867,  0.0524, -0.0371,\n",
            "         0.0727,  0.0172,  0.0492, -0.0743, -0.0663, -0.0841,  0.0348, -0.0127,\n",
            "        -0.0308, -0.0578,  0.0422,  0.0881, -0.0440,  0.0559, -0.0422,  0.0015,\n",
            "         0.0118,  0.0760,  0.0238, -0.0821, -0.0475,  0.0058,  0.0655, -0.0335,\n",
            "         0.0361, -0.0247,  0.0891, -0.0480,  0.0265,  0.0006, -0.0308,  0.0853,\n",
            "        -0.0674, -0.0705,  0.0900,  0.0736, -0.0498, -0.0558,  0.0161, -0.0613,\n",
            "        -0.0863, -0.0837,  0.0242, -0.0565,  0.0122, -0.0130,  0.0259,  0.0128,\n",
            "        -0.0893, -0.0699,  0.0769,  0.0622], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-9.5388e-02, -9.1761e-03,  1.5391e-02, -2.6037e-02, -6.5073e-02,\n",
            "          9.5098e-02,  3.9028e-02,  3.7357e-02, -7.1653e-02, -7.4152e-03,\n",
            "          8.4709e-02, -3.4512e-02, -5.8829e-02,  6.1953e-02,  7.3210e-02,\n",
            "         -2.5953e-02,  5.2825e-02,  8.7827e-02, -4.6057e-02, -3.4359e-02,\n",
            "          9.6416e-02, -6.5556e-02,  2.6421e-02, -1.1452e-02,  5.0013e-02,\n",
            "         -4.3240e-03,  8.8439e-02, -6.2498e-02, -7.2191e-03, -3.7012e-02,\n",
            "         -1.2579e-02,  7.3391e-02,  7.5595e-02, -9.6033e-02, -6.6760e-02,\n",
            "         -9.7330e-02, -7.2442e-02, -4.7791e-02,  4.4054e-02, -1.3696e-02,\n",
            "         -9.7561e-02, -6.0330e-02,  7.8544e-03, -9.7842e-02, -4.2765e-02,\n",
            "          1.0694e-02,  1.1544e-02, -2.5334e-02, -1.0881e-01, -4.3631e-02,\n",
            "          4.7186e-02,  1.2659e-02, -1.0459e-01, -6.6590e-02,  7.0898e-02,\n",
            "          5.0153e-02, -4.8046e-02, -7.8122e-02, -2.2800e-03,  9.0956e-02,\n",
            "         -4.4375e-03, -4.1741e-02, -2.5674e-02, -2.7531e-02,  1.7109e-02,\n",
            "         -9.7351e-02, -5.9943e-02,  4.6768e-02,  1.2469e-02, -5.8872e-02,\n",
            "         -2.5696e-02,  6.1008e-02,  6.8967e-02, -3.2835e-03, -9.2199e-02,\n",
            "         -8.7691e-02,  8.9861e-02,  8.8453e-02,  2.5989e-02,  9.1833e-02,\n",
            "          6.8456e-02,  7.6546e-03,  4.0827e-02, -9.5156e-02],\n",
            "        [-4.7834e-02,  3.9317e-02,  4.1481e-02, -5.8180e-02, -5.0371e-02,\n",
            "         -1.5511e-02,  2.7935e-02, -3.8177e-02,  4.8587e-03,  3.5157e-02,\n",
            "         -5.0348e-02,  2.4142e-02, -4.6192e-02,  3.2008e-02, -1.2896e-02,\n",
            "         -2.4171e-02,  7.7945e-02, -8.4501e-02, -1.6158e-02, -5.3898e-02,\n",
            "         -6.7022e-03,  1.3763e-02,  9.4536e-03,  8.7768e-02, -1.0337e-01,\n",
            "          1.0104e-01,  1.5853e-02, -2.3938e-02, -5.6819e-02,  1.0396e-01,\n",
            "          2.9041e-02, -5.1614e-02,  2.0621e-03,  6.5922e-03, -5.8322e-03,\n",
            "         -8.8172e-02,  2.8108e-02, -2.2682e-02, -1.7012e-02,  7.9875e-02,\n",
            "          4.5552e-02, -6.2176e-02,  4.6289e-03, -2.7768e-02,  3.5504e-02,\n",
            "          1.0290e-01, -4.4162e-02, -5.6883e-02,  1.2115e-02,  1.0404e-01,\n",
            "          8.9919e-04,  3.9230e-02, -9.8861e-02,  4.5788e-03, -8.7757e-02,\n",
            "          7.9203e-02, -9.1353e-02,  5.8924e-02, -2.5310e-02, -9.9011e-02,\n",
            "         -8.1215e-03, -4.6987e-02,  9.8786e-02, -7.1135e-02, -4.9032e-02,\n",
            "          7.8029e-02,  3.5960e-02,  5.9287e-02,  3.5513e-02, -3.8547e-02,\n",
            "          5.2070e-02,  3.4747e-02, -1.5207e-05, -8.7026e-02,  8.0858e-02,\n",
            "          4.4112e-02,  4.5617e-02, -7.2734e-02,  4.1915e-03,  9.1697e-02,\n",
            "          1.8636e-02, -7.1496e-02,  2.2718e-03,  4.2647e-03],\n",
            "        [-1.0556e-01, -1.0528e-01,  8.4029e-02,  6.6904e-02, -8.7530e-03,\n",
            "          1.4042e-02, -5.9553e-02, -9.1040e-02, -3.8395e-02, -8.9637e-02,\n",
            "         -4.7588e-02,  1.2840e-02, -7.4447e-02, -5.3409e-03,  6.8150e-02,\n",
            "          2.6859e-02, -9.6417e-02, -6.7470e-02,  6.7061e-02, -2.8645e-02,\n",
            "         -9.7388e-02, -4.9359e-02, -8.2389e-02,  6.9405e-02, -1.0038e-01,\n",
            "         -5.9820e-03,  1.0588e-01,  7.2833e-02, -7.8618e-02, -4.9673e-03,\n",
            "         -1.0699e-02,  7.4437e-02,  7.3156e-02, -1.5578e-02,  4.5868e-02,\n",
            "          8.7507e-02, -1.0900e-01,  2.7112e-02, -9.0943e-02,  8.7063e-02,\n",
            "          1.0732e-01, -4.5672e-02,  7.2461e-02, -3.2197e-02,  6.4810e-02,\n",
            "          9.0198e-02, -7.3813e-02, -3.2431e-02,  5.2627e-02, -7.7331e-02,\n",
            "          2.0639e-02,  1.3819e-02,  7.7425e-02, -6.6804e-02,  7.7136e-02,\n",
            "         -1.8650e-02, -1.0360e-01,  1.0836e-01,  4.6437e-03, -1.0790e-01,\n",
            "          4.8720e-02,  4.3682e-02,  8.1717e-02, -2.7874e-02, -8.3328e-02,\n",
            "         -9.7920e-02,  8.8653e-02, -9.2701e-02, -1.0316e-01, -6.7014e-02,\n",
            "         -4.0838e-02, -4.7190e-02, -7.8330e-02,  6.7162e-03,  1.0684e-01,\n",
            "          4.5373e-02, -9.2185e-02, -5.5035e-02, -1.5416e-03,  6.6948e-02,\n",
            "         -5.0745e-02, -1.4508e-02,  9.7929e-02, -7.5430e-02],\n",
            "        [ 3.0287e-02,  8.4354e-02, -8.2937e-02, -1.4222e-02, -4.1925e-02,\n",
            "         -1.0292e-01,  8.5739e-02, -6.7456e-02, -2.3693e-02, -7.9381e-02,\n",
            "         -8.4772e-02,  5.1888e-02,  8.2205e-02, -9.3583e-02, -5.1771e-02,\n",
            "         -1.8889e-02,  6.7377e-02,  1.0641e-01,  3.2252e-02, -2.8009e-03,\n",
            "          7.2412e-02, -3.2257e-02,  7.8559e-02,  3.5235e-02, -1.7839e-02,\n",
            "         -4.8309e-03,  1.0157e-01, -4.3423e-02,  4.1533e-02, -5.7170e-02,\n",
            "         -3.6064e-02,  4.0411e-02,  6.3269e-02, -4.9387e-02,  6.8539e-02,\n",
            "          8.8524e-02,  1.0803e-01, -8.5105e-02,  2.0597e-02,  4.7085e-02,\n",
            "         -1.0219e-01,  6.4843e-02,  7.2744e-02, -5.0086e-02,  1.0598e-01,\n",
            "          1.0589e-01, -2.5574e-02, -7.9616e-02,  6.5614e-02, -1.0255e-01,\n",
            "         -7.6150e-02, -2.6629e-03, -9.6449e-02,  6.1110e-03, -4.3076e-02,\n",
            "         -8.0587e-02,  3.1880e-02, -9.5148e-03,  3.2426e-02,  1.0657e-01,\n",
            "         -4.3353e-02,  1.9276e-03,  7.9730e-02,  7.9916e-02, -9.8189e-02,\n",
            "         -7.7676e-02,  4.5405e-02,  8.7767e-02, -5.4201e-02, -6.9036e-02,\n",
            "         -8.9425e-02, -8.7424e-02, -9.5295e-03,  7.0396e-02,  8.7768e-02,\n",
            "         -8.9776e-02,  1.5618e-02, -3.7680e-02,  1.0281e-01,  4.6432e-02,\n",
            "          1.0865e-02,  2.1825e-02,  2.7767e-02,  3.6060e-03],\n",
            "        [ 2.4437e-02,  8.3627e-02,  6.7462e-03, -9.8869e-02, -4.2028e-02,\n",
            "         -2.6619e-02,  7.3769e-02,  1.0095e-01,  1.1388e-02,  7.9730e-02,\n",
            "          1.0099e-01,  5.2283e-02,  6.2777e-02,  1.9591e-02, -9.7461e-02,\n",
            "         -3.8640e-02,  9.1449e-02, -4.0406e-02,  8.4135e-02, -3.7866e-02,\n",
            "          8.1046e-02, -9.0922e-02, -9.5999e-02, -3.5887e-02,  2.1344e-02,\n",
            "         -8.2539e-02,  6.2506e-02,  4.8229e-02,  4.2504e-03,  8.9229e-02,\n",
            "         -8.6163e-02,  4.3649e-02,  7.0147e-02,  4.6592e-02, -2.5521e-02,\n",
            "         -3.3342e-02,  1.2606e-02,  3.8421e-02, -2.7080e-02,  7.7300e-02,\n",
            "         -1.8990e-02,  8.4247e-02,  8.5106e-02,  9.6470e-02, -5.0870e-02,\n",
            "         -7.1687e-02, -1.3302e-02, -1.9404e-02,  8.8775e-02,  5.2102e-02,\n",
            "         -5.8177e-02, -1.0935e-02, -1.0719e-01, -2.9011e-02, -6.8553e-02,\n",
            "          7.6062e-02,  5.6192e-03, -9.5457e-02, -1.0940e-02,  8.4299e-03,\n",
            "          4.7527e-02, -3.0198e-02, -9.2109e-02, -7.8819e-03, -2.3087e-02,\n",
            "         -7.8373e-03, -1.4200e-02, -1.6001e-02, -1.7332e-03, -4.0805e-02,\n",
            "          6.2325e-03, -8.6267e-02,  6.3710e-02, -7.8228e-02,  6.9122e-02,\n",
            "          2.5797e-02, -8.6379e-02, -4.3970e-02, -7.1257e-02,  3.3986e-02,\n",
            "          9.6121e-02, -2.1276e-02, -3.1398e-02, -8.6194e-02],\n",
            "        [ 1.2288e-02, -6.8601e-02,  3.9832e-02,  1.0303e-01,  4.9209e-03,\n",
            "          9.6992e-03,  7.1731e-02, -8.7021e-03,  2.5867e-02, -1.7426e-02,\n",
            "         -1.8162e-02, -2.5568e-03,  1.0389e-01,  7.8083e-02,  8.7499e-02,\n",
            "         -7.2442e-02,  4.5804e-02, -9.5543e-02,  9.6951e-02,  7.8215e-02,\n",
            "          2.5290e-02,  2.4574e-02, -8.8500e-02,  1.0632e-01,  8.9170e-02,\n",
            "         -1.7480e-02,  7.6720e-02, -3.8488e-02, -2.6231e-02, -1.9454e-02,\n",
            "          6.6608e-02, -1.3169e-02, -6.1130e-02,  8.2624e-02, -1.0027e-01,\n",
            "          4.7434e-02,  7.6947e-02, -8.7226e-02,  2.6631e-02,  1.3012e-02,\n",
            "         -1.8181e-02, -3.2650e-02,  9.8039e-03,  2.9969e-03,  7.7729e-02,\n",
            "         -3.4629e-02,  7.7890e-02,  8.3828e-03,  3.0036e-02,  5.8249e-03,\n",
            "          5.6518e-02,  9.8786e-02, -1.5390e-02, -1.0595e-01,  1.4715e-02,\n",
            "         -6.3368e-02,  9.7403e-02,  2.1750e-02, -9.1725e-02, -6.7249e-03,\n",
            "         -2.4186e-02, -7.4256e-02, -3.0212e-02, -9.7454e-03, -8.6659e-02,\n",
            "         -7.8166e-02, -1.0099e-01,  8.7605e-02,  1.1616e-02, -5.1601e-02,\n",
            "          1.0835e-02,  1.2924e-02, -5.6914e-02, -7.1365e-02,  7.4168e-02,\n",
            "          4.1606e-02, -3.1127e-02,  8.8936e-02, -2.0544e-02,  5.9095e-02,\n",
            "          7.5915e-02, -6.8680e-02, -1.8439e-02, -4.5168e-02],\n",
            "        [ 9.4554e-03, -8.7212e-02,  3.6590e-02, -4.3574e-02,  7.8942e-02,\n",
            "         -5.6870e-02, -3.5335e-02, -3.7886e-02, -5.5179e-02,  8.0995e-02,\n",
            "         -9.1094e-02,  1.0868e-01,  2.8263e-02, -5.6465e-02, -7.6363e-02,\n",
            "          9.8262e-02,  2.3526e-02, -7.0310e-03, -6.8721e-02, -6.1008e-02,\n",
            "          1.0062e-01,  6.7399e-02,  1.8814e-02,  2.4011e-02,  1.0096e-02,\n",
            "          6.0977e-02, -2.9436e-02,  4.8924e-02,  1.0643e-01,  6.6107e-02,\n",
            "         -1.4106e-02,  9.7393e-02,  1.0225e-01,  8.3799e-02,  2.4449e-02,\n",
            "          2.6174e-03,  3.2856e-02, -4.3489e-02, -4.0845e-02,  1.0342e-01,\n",
            "          2.6286e-02, -9.2271e-02, -6.7287e-02,  6.0832e-02, -2.6273e-02,\n",
            "          5.9391e-03, -9.4210e-02,  3.5626e-03, -1.5955e-02, -1.8414e-02,\n",
            "          9.5935e-02, -1.0446e-01,  2.1717e-02, -5.3569e-02,  3.4620e-02,\n",
            "          6.0153e-02, -6.9155e-02, -6.4028e-02, -1.0153e-01,  6.8079e-02,\n",
            "          1.5638e-02,  4.4881e-02,  1.0170e-01, -9.9633e-02, -7.9040e-02,\n",
            "         -8.0926e-02,  7.2506e-02,  4.8678e-02, -7.6447e-02,  5.3111e-02,\n",
            "         -1.8025e-02, -9.7750e-04,  6.4125e-02, -1.2139e-02,  3.6957e-02,\n",
            "         -1.0167e-01, -9.2668e-02, -1.0062e-02, -9.6147e-02,  7.0514e-02,\n",
            "         -8.1143e-02,  9.1963e-02, -1.0499e-01, -8.1471e-04],\n",
            "        [ 7.2016e-02, -2.5863e-02,  9.3566e-02, -7.8985e-02,  7.4883e-02,\n",
            "          5.6471e-02, -3.0509e-02,  8.0648e-02, -6.6236e-02,  3.9902e-02,\n",
            "         -1.2280e-02,  9.2940e-02,  4.7534e-02,  6.1303e-02,  6.0932e-02,\n",
            "          9.4937e-02,  4.8496e-02, -9.6360e-02, -6.5712e-03,  5.9035e-02,\n",
            "         -4.3282e-02,  3.3896e-02,  9.2572e-04, -6.7395e-02, -1.4690e-02,\n",
            "          2.8088e-03,  9.5918e-02, -3.2303e-02,  3.8304e-02,  6.0942e-02,\n",
            "         -1.0738e-01,  9.0338e-03,  2.7470e-02, -1.4425e-02, -8.4950e-02,\n",
            "         -2.5558e-02, -1.7922e-02,  4.9165e-02,  8.3678e-02,  3.9715e-02,\n",
            "          6.0909e-02, -2.9067e-02, -4.3315e-02,  5.7035e-02, -1.7176e-02,\n",
            "          6.5938e-02, -3.1104e-02,  7.2339e-02, -1.0718e-01, -8.0992e-02,\n",
            "         -3.0787e-02,  3.2069e-02, -3.9470e-02,  3.5961e-02, -9.7555e-02,\n",
            "          8.3277e-02,  4.6574e-02,  2.0198e-02, -7.6538e-02, -7.1542e-02,\n",
            "          1.0341e-01,  2.0681e-02, -1.3328e-02, -9.4239e-02, -7.7492e-02,\n",
            "          2.1752e-02,  7.4851e-02,  4.9653e-02,  7.0836e-02, -7.4557e-02,\n",
            "          7.6968e-02, -5.9328e-02, -2.9566e-02, -5.8508e-02, -9.8552e-02,\n",
            "         -1.5557e-05,  4.3899e-02, -1.0368e-01, -1.7741e-02,  3.5034e-02,\n",
            "          2.8970e-02, -9.9454e-02,  7.7997e-02, -3.9703e-03],\n",
            "        [ 7.8980e-02, -6.6298e-02, -9.2911e-02,  4.4145e-02,  6.7561e-02,\n",
            "          6.7524e-02,  3.0631e-02,  7.7976e-02,  2.1611e-02, -3.8594e-02,\n",
            "          6.6857e-02, -9.1527e-02,  8.6853e-02,  7.8891e-02, -4.9940e-02,\n",
            "         -9.8127e-02,  9.2768e-02, -4.9558e-02,  8.1008e-02, -4.9347e-02,\n",
            "          7.5986e-02,  9.2148e-02, -8.9906e-02,  1.9484e-02, -9.3989e-02,\n",
            "          3.4602e-02,  7.0697e-03,  3.4783e-02,  1.0658e-01,  8.0973e-02,\n",
            "          7.5797e-03,  3.8145e-02, -9.0577e-03, -2.2174e-03, -5.0521e-02,\n",
            "          7.3660e-02,  6.6582e-02, -5.3291e-02,  5.3128e-02, -8.6797e-02,\n",
            "         -7.2671e-02, -6.2058e-02, -3.8200e-02, -7.2387e-02, -3.9852e-02,\n",
            "          6.7456e-02,  1.0717e-01,  8.2915e-02, -9.5958e-02, -4.5566e-02,\n",
            "          2.7750e-02,  8.3703e-02, -1.0108e-01, -5.5727e-03,  3.4912e-03,\n",
            "         -3.1512e-03, -5.2763e-02,  7.7069e-04,  2.4105e-02,  7.6761e-02,\n",
            "         -1.6592e-02, -4.5618e-02, -2.9928e-03,  9.6281e-02, -6.3679e-02,\n",
            "         -4.1010e-03,  2.9049e-02,  2.9353e-02, -4.7503e-02,  6.3022e-03,\n",
            "          9.0437e-02,  1.5647e-02,  5.1024e-02, -9.6900e-02,  2.0254e-02,\n",
            "         -1.2848e-02, -9.5225e-02, -4.0649e-02,  8.6353e-02,  1.8649e-02,\n",
            "          4.8289e-02, -9.8693e-02,  9.2848e-02,  3.4468e-02],\n",
            "        [-9.4516e-02, -5.8402e-02, -1.0625e-01,  1.9414e-02, -5.1324e-02,\n",
            "          9.8657e-02,  5.7380e-02, -2.8335e-02,  1.8083e-02, -4.7993e-02,\n",
            "         -1.0435e-01, -1.0693e-01, -9.2929e-02,  6.3054e-02,  9.4075e-02,\n",
            "         -1.2439e-02, -8.6255e-02,  9.8244e-02,  2.7030e-02, -8.3222e-03,\n",
            "         -1.0375e-01, -8.4033e-02, -1.0487e-01, -5.1714e-02,  6.7962e-02,\n",
            "         -1.0443e-01, -3.8055e-02,  8.4073e-02,  1.4817e-02, -3.6008e-03,\n",
            "         -8.8535e-02,  5.0093e-02, -3.6021e-02, -4.2919e-02, -4.0599e-02,\n",
            "          2.6259e-02,  2.0959e-02,  1.0268e-01,  1.6451e-02, -5.1360e-02,\n",
            "         -9.2528e-02,  7.1318e-02,  8.9767e-02, -4.7960e-03,  1.0710e-01,\n",
            "          3.1826e-02, -1.0746e-01, -9.5444e-03, -1.0684e-01,  5.3797e-02,\n",
            "          9.6411e-02, -2.9980e-02, -4.9745e-02, -2.5021e-02,  9.2604e-03,\n",
            "          1.0270e-03,  5.4925e-03, -3.7911e-02, -7.6130e-02, -1.0436e-01,\n",
            "         -2.3900e-02,  3.2401e-02,  5.8459e-02,  2.3684e-02, -5.5586e-02,\n",
            "         -1.0867e-01, -4.5180e-02,  1.0249e-01, -1.0280e-03, -5.7413e-02,\n",
            "          3.6511e-02, -7.9186e-02, -8.4263e-02,  1.0305e-01, -1.0222e-01,\n",
            "          2.9231e-03, -2.6823e-02,  5.4418e-02,  2.7490e-02, -8.6664e-02,\n",
            "          5.6557e-02, -1.0222e-01, -9.0921e-02,  5.6944e-02]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0350,  0.0870, -0.0276,  0.0652,  0.0878,  0.0836, -0.0261,  0.0465,\n",
            "        -0.1033,  0.0919], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SznDA9tVgALg",
        "colab_type": "text"
      },
      "source": [
        "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: torch.optim that implements all these methods. Using it is very simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRn2EzZffpWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sH2l-QvgDB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}